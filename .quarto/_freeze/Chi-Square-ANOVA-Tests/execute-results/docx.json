{
  "hash": "6605c23abd8e1a3522f5515396508ada",
  "result": {
    "markdown": "---\ntitle: \"Chi-squared-ANOVA-Tests\"\nauthor: \"Kathryn Kozak\"\nformat: docx\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mosaic)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'mosaic'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:Matrix':\n\n    mean\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggplot2':\n\n    stat\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n```\n:::\n:::\n\n\n# Chi-Square and ANOVA Tests\n\nThis chapter presents material on three more hypothesis tests. One is used to determine significant relationship between two qualitative variables, the second is used to determine if the sample data has a particular distribution, and the last is used to determine significant relationships between means of 3 or more samples.\n\n## Chi-Square Test for Independence\n\nRemember, qualitative data is where you collect data on individuals that are categories or names. Then you would count how many of the individuals had particular qualities. An example is that there is a theory that there is a relationship between breastfeeding and autism. To determine if there is a relationship, researchers could collect the time period that a mother breastfed her child and if that child was diagnosed with autism. Then you would have a table containing this information. Now you want to know if each cell is independent of each other cell. Remember, independence says that one event does not affect another event. Here it means that having autism is independent of being breastfed. What you really want is to see if they are not independent. In other words, does one affect the other? If you were to do a hypothesis test, this is your alternative hypothesis and the null hypothesis is that they are independent. There is a hypothesis test for this and it is called the **Chi-Square Test for Independence**. Technically it should be called the Chi-Square Test for Dependence, but for historical reasons it is known as the test for independence. Just as with previous hypothesis tests, all the steps are the same except for the conditions and the test statistic.\n\n## Hypothesis Test for Chi-Square Test\n\n1.  State the null and alternative hypotheses and the level of significance\n\n$H_o:$ the two variables are independent (this means that the one variable is not affected by the other)\n\n$H_a:$ the two variables are dependent (this means that the one variable is affected by the other)\n\nAlso, state your $\\alpha$ level here.\n\n2.  State and check the conditions for the hypothesis test\n\n<!-- -->\n\na.  A random sample is taken.\n\nb.  Expected frequencies for each cell are greater than or equal to 5 (The expected frequencies, $E$, will be calculated later, and this condition means $E\\ge5$).\n\n3\\. Find the test statistic and p-value\n\nFinding the test statistic involves several steps. First the data is collected and counted, and then it is organized into a table (in a table each entry is called a cell). These values are known as the observed frequencies, which the symbol for an observed frequency is $O$. Each table is made up of rows and columns. Then each row is totaled to give a row total and each column is totaled to give a column total.\n\nThe null hypothesis is that the variables are independent. Using the multiplication rule for independent events you can calculate the probability of being one value of the first variable, $A$, and one value of the second variable, $B$ (the probability of a particular cell). Remember in a hypothesis test, you assume that is true, the two variables are assumed to be independent.\n\nNow you want to find out how many individuals you expect to be in a certain cell. To find the expected frequencies, you just need to multiply the probability of that cell times the total number of individuals. Do not round the expected frequencies.\n\nIf the variables are independent the expected frequencies and the observed frequencies should be the same. The test statistic here will involve looking at the difference between the expected frequency and the observed frequency for each cell. Then you want to find the \"total difference\" of all of these differences. The larger the total, the smaller the chances that you could find that test statistic given that the condition of independence is true. That means that the condition of independence is not true. How do you find the test statistic? First find the differences between the observed and expected frequencies. Because some of these differences will be positive and some will be negative, you need to square these differences. These squares could be large just because the frequencies are large, you need to divide by the expected frequencies to scale them. Then finally add up all of these fractional values. This is the test statistic.\n\nTest Statistic:\n\nUsing r: See example 11.1.1 for the process\n\n4.  Conclusion\n\nThis is where you write reject $H_o$ or fail to reject $H_o$. The rule is: if the p-value $<\\alpha$, then reject $H_o$. If the p-value$\\ge \\alpha$, then fail to reject $H_o$\n\n5.  Interpretation\n\nThis is where you interpret in real world terms the conclusion to the test. The conclusion for a hypothesis test is that you either have enough evidence to support $H_a$, or you do not have enough evidence to support $H_a$.\n\n### Example: Hypothesis Test with Chi-Square Test\n\nIs there a relationship between autism and breastfeeding? To determine if there is, a researcher asked mothers of autistic and non-autistic children to say what time period they breastfed their children. The data is in table #11.1.1 (Schultz, Klonoff-Cohen, Wingard, Askhoomoff, Macera, Ji & Bacher, 2006). Do the data provide enough evidence to support that breastfeeding and autism are independent? Test at the 1% level.\n\n##### Table #11.1.1: Autism Versus Breastfeeding\n\n| Austism | Not Breast Feed | Breast Feed less than 2 months | Breast Feed 2 to 6 months | Breast Feed more than 6 months |\n|---------------|---------------|---------------|---------------|---------------|\n| yes     | 241             | 198                            | 164                       | 215                            |\n| no      | 20              | 25                             | 27                        | 44                             |\n\n: Breast Feeding\n\nTo put this data into r, use the following commands:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n    [,1] [,2] [,3] [,4]\nyes  241  198  164  215\nno    20   25   27   44\n```\n:::\n:::\n\n\nwhere \\[,1\\] represents number of mothers who did not breast feed, \\[,2\\] represents number of mothers who breast feed for less than 2 months, \\[,3\\] represents number of mothers who breast feed between 2 and 6 months. and \\[,4\\] represents the number of mothers who breast feed more than 6 months. Rows represent whether children has or doesn't have autism.\n\nIf you have the dataset instead of the summary table as in this example, you can use the tally command to create the table in r. Just save the tally command with a name.\n\n#### Solution\n\n1.  State the null and alternative hypotheses and the level of significance\n\n$H_o$: Breastfeeding and autism are independent\n\n$H_a$: Breastfeeding and autism are dependent\n\n2.  State and check the conditions for the hypothesis test\n\n<!-- -->\n\na.  A random sample of breastfeeding time frames and autism incidence was taken. Check: this was stated in the problem.\n\nb.  Expected frequencies for each cell are greater than or equal to 5, $E\\ge 5$. See step 3. All expected frequencies are more than 5.\n\n<!-- -->\n\n3.  Find the test statistic and p-value On r Studio, the command is\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchisq.test(autism_table) #calculates the test statistics and p-value \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  autism_table\nX-squared = 11.217, df = 3, p-value = 0.01061\n```\n:::\n\n```{.r .cell-code}\nchisq.test(autism_table)$expected # shows all the expected frequencies \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         [,1]      [,2]      [,3]      [,4]\nyes 228.58458 195.30407 167.27837 226.83298\nno   32.41542  27.69593  23.72163  32.16702\n```\n:::\n:::\n\n\nThe test statistic is 11.217 and the p-value is 0.01061.\n\n4.  Conclusion\n\nFail to reject $H_o$ since the p-value is more than 0.01.\n\n5.  Interpretation\n\nThere is not enough evidence to support that breastfeeding and autism are dependent. This means that you cannot say whether a child is breastfed or not will indicate if that the child will be diagnosed with autism.\n\n### Homework\n\n**In each problem show all steps of the hypothesis test. If some of the conditions are not met, note that the results of the test may not be correct and then continue the process of the hypothesis test.**\n\n1.  The number of people who survived the Titanic based on class and sex is in table #11.1.2 (\"Encyclopedia Titanica,\" 2013). Is there enough evidence to show that the class and the sex of a person who survived the Titanic are independent? Test at the 5% level.\n\n##### Table #11.1.2: Surviving the Titanic\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n        sex\nclass    female male\n  first     134   59\n  second     94   25\n  third      80   58\n```\n:::\n:::\n\n\n2.  Researchers watched groups of dolphins off the coast of Ireland in 1998 to determine what activities the dolphins partake in at certain times of the day (\"Activities of dolphin,\" 2013). The numbers in table #11.1.3 represent the number of groups of dolphins that were partaking in an activity at certain times of days. Is there enough evidence to show that the activity and the time period are independent for dolphins? Test at the 1% level.\n\n##### Table #11.1.3: Dolphin Activity\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDolphin<- read.csv( \"https://krkozak.github.io/MAT160/dolphins.csv\") \nDolphin_table<-tally(~activity+period, data=Dolphin)\nDolphin_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        period\nactivity Afternoon Evening Morning Noon\n  Feed           0      56      28    4\n  Social         9      10      38    5\n  Travel        14      13       6    6\n```\n:::\n:::\n\n\n3.  Is there a relationship between autism and what an infant is fed? To determine if there is, a researcher asked mothers of autistic and non-autistic children to say what they fed their infant. The data is in table #11.1.4 (Schultz, Klonoff-Cohen, Wingard, Askhoomoff, Macera, Ji & Bacher, 2006). Do the data provide enough evidence to show that that what an infant is fed and autism are independent? Breast-feeding (BF), Formula with DHA/ARA (For with), and Formula without DHA/ARA (Form without)Test at the 1% level.\n\n##### Table #11.1.4: Autism Versus Breastfeeding\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFeeding<- read.csv( \"https://krkozak.github.io/MAT160/Mothers.csv\") \nFeeding_table<-tally(~autism+feeding, data=Feeding)\nFeeding_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      feeding\nautism breast formula_with formula_without\n   no       6           22              10\n   yes     12           39              65\n```\n:::\n:::\n\n\n4.  Students at multiple grade schools were asked what their personal goal (get good grades, be popular, be good at sports) was and how important good grades were to them (1 very important and 4 least important). The data is in table #11.1.6 (\"Popular kids datafile,\" 2013). Do the data provide enough evidence to show that goal attainment and importance of grades are independent? Test at the 5% level.\n\n##### Table #11.1.6: Personal Goal and Importance of Grades\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGoal<- read.csv( \"https://krkozak.github.io/MAT160/Popular_Kids_clean.csv\") \nGoal_Grades_table<-tally(~Goals+Grades, data=Goal)\nGoal_Grades_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Grades\nGoals      1  2  3  4\n  Grades  70 66 55 56\n  Popular 14 33 45 49\n  Sports  10 24 33 23\n```\n:::\n:::\n\n\n5.  Students at multiple grade schools were asked what their personal goal (get good grades, be popular, be good at sports) was and how important being good at sports were to them (1 very important and 4 least important). The data is in table #11.1.7 (\"Popular kids datafile,\" 2013). Do the data provide enough evidence to show that goal attainment and importance of sports are independent? Test at the 5% level.\n\nTable #11.1.7: Personal Goal and Importance of Sports\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGoal<- read.csv( \"https://krkozak.github.io/MAT160/Popular_Kids_clean.csv\") \nGoal_Sports_table<-tally(~Goals+Sports, data=Goal)\nGoal_Sports_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Sports\nGoals      1  2  3  4\n  Grades  83 81 55 28\n  Popular 32 49 43 17\n  Sports  50 24 14  2\n```\n:::\n:::\n\n\n6.  Students at multiple grade schools were asked what their personal goal (get good grades, be popular, be good at sports) was and how important having good looks were to them (1 very important and 4 least important). The data is in table #11.1.8 (\"Popular kids datafile,\" 2013). Do the data provide enough evidence to show that goal attainment and importance of looks are independent? Test at the 5% level.\n\n##### Table #11.1.8: Personal Goal and Importance of Looks\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGoal<- read.csv( \"https://krkozak.github.io/MAT160/Popular_Kids_clean.csv\") \nGoal_Looks_table<-tally(~Goals+Looks, data=Goal)\nGoal_Looks_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Looks\nGoals      1  2  3  4\n  Grades  80 66 66 35\n  Popular 81 30 18 12\n  Sports  24 30 17 19\n```\n:::\n:::\n\n\n7.  Students at multiple grade schools were asked what their personal goal (get good grades, be popular, be good at sports) was and how important having money were to them (1 very important and 4 least important). The data is in table #11.1.9 (\"Popular kids datafile,\" 2013). Do the data provide enough evidence to show that goal attainment and importance of money are independent? Test at the 5% level.\n\n##### Table #11.1.9: Personal Goal and Importance of Money\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGoal<- read.csv( \"https://krkozak.github.io/MAT160/Popular_Kids_clean.csv\") \nGoal_Money_table<-tally(~Goals+Money, data=Goal)\nGoal_Money_table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Money\nGoals       1   2   3   4\n  Grades   14  34  71 128\n  Popular  14  29  35  63\n  Sports    6  12  26  46\n```\n:::\n:::\n\n\n\\*\\*\\\\ \\*\\*\n\n## Chi-Square Goodness of Fit\n\nIn probability, you calculated probabilities using both experimental and theoretical methods. There are times when it is important to determine how well the experimental values match the theoretical values. An example of this is if you wish to verify if a die is fair. To determine if observed values fit the expected values, you want to see if the difference between observed values and expected values is large enough to say that the test statistic is unlikely to happen if you assume that the observed values fit the expected values. The test statistic in this case is also the chi-square. The process is the same as for the chi-square test for independence.\n\n### Hypothesis Test for Goodness of Fit Test\n\n1.  State the null and alternative hypotheses and the level of significance\n\n$H_o:$ The data are consistent with a specific distribution\n\n$H_a:$ The data are not consistent with a specific distribution\n\nAlso, state your $\\alpha$ level here.\n\n2.  State and check the conditions for the hypothesis test\n\n<!-- -->\n\na.  A random sample is taken.\n\nb.  Expected frequencies for each cell are greater than or equal to 5 (The expected frequencies, \\*E\\*, will be calculated later).\n\n<!-- -->\n\n3.  Find the test statistic and p-value\n\nUsing r Studio see example 11.2.1\n\n4.  Conclusion\n\nThis is where you write reject $H_o$ or fail to reject $H_o$. The rule is: if the p-value $<\\alpha$, then reject $H_o$. If the p-value $\\ge \\alpha$, then fail to reject $H_0$\n\n5.  Interpretation\n\nThis is where you interpret in real world terms the conclusion to the test. The conclusion for a hypothesis test is that you either have enough evidence to support $H_a$, or you do not have enough evidence to support $H_a$.\n\n### Example: Goodness of Fit Test\n\nSuppose you have a die that you are curious if it is fair or not. If it is fair then the proportion for each value should be the same. You need to find the observed frequencies and to accomplish this you roll the die 500 times and count how often each side comes up. The data is in table #11.2.1. Do the data show that the die is fair? Test at the 5% level.\n\n##### Table #11.2.1: Observed Frequencies of Die for sides 1 through 6\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 78 87 87 76 85 87\n```\n:::\n:::\n\n\n#### Solution\n\n1.  State the null and alternative hypotheses and the level of significance\n\n$H_o:$ The observed frequencies are consistent with the distribution for fair die (the die is fair)\n\n$H_a:$ The observed frequencies are not consistent with the distribution for fair die (the die is not fair)\n\n$\\alpha=0.05$\n\n2.  State and check the conditions for the hypothesis test\n\n<!-- -->\n\na.  A random sample is taken. check: This is true since each throw of a die is a random event.\nb.  Expected frequencies for each cell are greater than or equal to 5. See step 3.\n\n<!-- -->\n\n3.  Find the test statistic and p-value\n\nOn r Studio, this would be\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfair_die<-c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6) \nobserved<-c(78, 87, 87, 76, 85, 87) \nchisq.test(observed, p=fair_die) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tChi-squared test for given probabilities\n\ndata:  observed\nX-squared = 1.504, df = 5, p-value = 0.9126\n```\n:::\n\n```{.r .cell-code}\nchisq.test(observed, p=fair_die)$expected \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 83.33333 83.33333 83.33333 83.33333 83.33333 83.33333\n```\n:::\n:::\n\n\nTest Statistic: The test statistic is 1.504. The p-value is 0.9126.\n\n4.  Conclusion\n\nFail to reject $H_o$ since the p-value is greater than 0.05.\n\n5.  Interpretation\n\nThere is not enough evidence to support that the die is not consistent with the distribution for a fair die. There is not enough evidence to support that the die is not fair.\n\n### Homework\n\n**In each problem show all steps of the hypothesis test. If some of the conditions are not met, note that the results of the test may not be correct and then continue the process of the hypothesis test.**\n\n1.  According to the M&M candy company, the expected proportion can be found in Table #11.2.2. In addition, the table contains the number of M&M's of each color that were found in a case of candy (Madison, 2013). At the 5% level, do the observed frequencies support the claim of M&M?\n\n##### Table #11.2.2: M&M Observed and Expected\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMaM<- read.csv( \"https://krkozak.github.io/MAT160/M_and_Ms.csv\") \nobserved<-tally(~color, data=MaM)\nexpected<-c(0.24, 0.13, .16, 0.2, 0.13, 0.14)\nobserved\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncolor\n  blue  brown  green orange    red yellow \n   481    371    483    544    372    369 \n```\n:::\n\n```{.r .cell-code}\nexpected\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.24 0.13 0.16 0.20 0.13 0.14\n```\n:::\n:::\n\n\n| Frequency | Blue | brown | Green | Orange | Red  | Yellow |\n|-----------|------|-------|-------|--------|------|--------|\n| Observed  | 481  | 371   | 483   | 544    | 372  | 369    |\n| Expected  | 0.24 | 0.13  | 0.16  | 0.2    | 0.13 | 0.14   |\n\n: M&M Color Distribution\n\n2.  Eyeglassomatic manufactures eyeglasses for different retailers. They test to see how many defective lenses they made the time period of January 1 to March 31. Table #11.2.3 gives the defect and the number of defects.\n\n##### Table #11.2.3: Number of Defective Lenses\n\n| scratch | Right shaped- small | Flaked | wrong axis | Camfer | Crazing | Wrong Shape | Wrong PD | Spots | Wrong height | Right shape- big | Lost in lab | Spots - interm |\n|------|------|------|------|------|------|------|------|------|------|------|------|------|\n| 5865    | 4613                | 1992   | 1838       | 1596   | 1546    | 1485        | 1398     | 1371  | 1130         | 1105             | 976         | 976            |\n\n: Observed Defects\n\nDo the data support the notion that each defect type occurs in the same proportion? Test at the 5% level.\n\n3.  On occasion, medical studies need to model the proportion of the population that has a disease and compare that to observed frequencies of the disease actually occurring. Suppose the end-stage renal failure in south-west Wales was collected for different age groups. Do the data in table 11.2.4 show that the observed frequencies are in agreement with proportion of people in each age group (Boyle, Flowerdew & Williams, 1997)? Test at the 1% level.\n\n    Table #11.2.4: Renal Failure Frequencies\n\n    | Age Group          | 16-29 | 30-44 | 45-59 | 60-75 | 75+  |\n    |--------------------|-------|-------|-------|-------|------|\n    | Observed Frequency | 32    | 66    | 132   | 218   | 91   |\n    | Expected frequency | 0.23  | 0.25  | 0.22  | 0.21  | 0.09 |\n\n    : Renal Failure\n\n4.  In Africa in 2011, the number of deaths of a female from cardiovascular disease for different age groups are in table #11.2.5 (\"Global health observatory,\" 2013). In addition, the proportion of deaths of females from all causes for the same age groups are also in table #11.2.5. Do the data show that the death from cardiovascular disease are in the same proportion as all deaths for the different age groups? Test at the 5% level.\n\n    ##### Table #11.2.5: Deaths of Females for Different Age Groups\n\n| Age                | 5-14 | 14-29 | 30-49 | 50-69 |\n|--------------------|------|-------|-------|-------|\n| Observed Frequency | 8    | 16    | 56    | 433   |\n| Expected Frequency | 0.10 | 0.12  | 0.26  | 0.52  |\n\n: Deaths of Females\n\n5.  In Australia in 1995, there was a question of whether indigenous people are more likely to die in prison than non-indigenous people. To figure out, the data in table 11.2.6 was collected. (\"Aboriginal deaths in,\" 2013). Do the data show that indigenous people die in the same proportion as non-indigenous people? Test at the 1% level.\n\n    ##### Table #11.2.6: Death of Prisoners\n\n    | Prisoner Died       | Yes   | No    |\n    |---------------------|-------|-------|\n    | Observed Indigenous | 17    | 3890  |\n    | Expected frequency  | 0.003 | 0.997 |\n\n    : Death of Indigenous Prisoners\n\n6.  A project conducted by the Australian Federal Office of Road Safety asked people many questions about their cars. One question was the reason that a person chooses a given car, and that data is in table #11.2.7 (\"Car preferences,\" 2013).\n\n##### Table #11.2.7: Reason for Choosing a Car\n\n| Reason             | Safety | reliability | Cost | Performance | Comfort | Looks |\n|--------------------|--------|-------------|------|-------------|---------|-------|\n| Observed Frequency | 84     | 62          | 46   | 34          | 47      | 27    |\n\n: Reason for Choosing a Car\n\nDo the data show that the frequencies observed substantiate the claim that the reasons for choosing a car are equally likely? Test at the 5% level.\n\n## Analysis of Variance (ANOVA)\n\nThere are times where you want to compare three or more population means. One idea is to just test different combinations of two means. The problem with that is that your chance for a type I error increases. Instead you need a process for analyzing all of them at the same time. This process is known as **analysis of variance (ANOVA)**. The test statistic for the ANOVA is fairly complicated, you will want to use technology to find the test statistic and p-value. The test statistic is distributed as an F-distribution, which is skewed right and depends on degrees of freedom. Since you will use technology to find these, the distribution and the test statistic will not be presented. Remember, all hypothesis tests are the same process. Note that to obtain a statistically significant result there need only be a difference between any two of the $k$ means.\n\nBefore conducting the hypothesis test, it is helpful to look at the means and standard deviations for each data set. If the sample means with consideration of the sample standard deviations are different, it may mean that some of the population means are different. However, do realize that if they are different, it doesn't provide enough evidence to show the population means are different. Calculating the sample statistics just gives you an idea that conducting the hypothesis test is a good idea.\n\n### Hypothesis test using ANOVA to compare $k$ means\n\n1.  State the random variables and the parameters in words\n\n2.  State the null and alternative hypotheses and the level of significance\n\n$H_o:$ all the means are the same\n\n$H_a:$ at least two of the means are different\n\nAlso, state your $\\alpha$ level here.\n\n3.  State and check the conditions for the hypothesis test\n\na\\. A random sample of size is taken from each population.\n\nb.  All the samples are independent of each other.\n\nc.  Each population is normally distributed. The ANOVA test is fairly robust to the condition especially if the sample sizes are fairly close to each other. Unless the populations are really not normally distributed and the sample sizes are close to each other, then this is a loose condition.\n\nd.  The population variances are all equal. If the sample sizes are close to each other, then this is a loose condition.\n\n4\\. Find the test statistic and p-value\n\nThe test statistic is $F$. To find the test statistic, use technology such r Studio.\n\nThe test statistic, $F$, is distributed as an F-distribution, where both degrees of freedom are needed in this distribution. The p-value is also calculated r Studio.\n\n5.  Conclusion\n\nThis is where you write reject $H_O$ or fail to reject $H_O$. The rule is: if the p-value $<\\alpha$, then reject $H_o$. If the p-value $\\ge \\alpha$, then fail to reject $H_o$\n\n6.  Interpretation\n\nThis is where you interpret in real world terms the conclusion to the test. The conclusion for a hypothesis test is that you either have enough evidence to support $H_a$, or you do not have enough evidence to support $H_a$.\n\nIf you do in fact reject $H_o$, then you know that at least two of the means are different. The next question you might ask is which are different? You can look at the sample means, but realize that these only give a preliminary result. To actually determine which means are different, you need to conduct other tests. Some of these tests are the range test, multiple comparison tests, Duncan test, Student-Newman-Keuls test, Tukey test, Scheffé test, Dunnett test, least significant different test, and the Bonferroni test. There is no consensus on which test to use.\n\n### Example: Hypothesis Test Involving Several Means\n\nCancer is a terrible disease. Surviving may depend on the type of cancer the person has. To see if the mean survival time for several types of cancer are different, data was collected on the survival time in days of patients with one of these cancer in advanced stage. The data is in table #11.3.1 (\"Cancer survival story,\" 2013). (Please realize that this data is from 1978. There have been many advances in cancer treatment, so do not use this data as an indication of survival rates from these cancers.) Do the data indicate that at least two of the mean survival time for these types of cancer are not all equal? Test at the 1% level.\n\n##### Table #11.3.1: Survival Times in Days of Five Cancer Types\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCancer <- read.csv( \"https://krkozak.github.io/MAT160/cancer.csv\") \nhead(Cancer)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  survival   organ\n1      124 Stomach\n2       42 Stomach\n3       25 Stomach\n4       45 Stomach\n5      412 Stomach\n6       51 Stomach\n```\n:::\n:::\n\n\n###### Code book for data frame Cancer\n\nDescription Survival time for several types of cancer was collected.\n\nThis data frame contains the following columns:\n\nsurvival: survival times (months)\n\norgan: the organ that the cancer is in\n\nSource Cancer survival story. (2013, December 04). Retrieved from \\<http://lib.stat.cmu.edu/DASL/Stories/CancerSurvival.html\\>\n\nReferences \\<http://lib.stat.cmu.edu/DASL\\>\n\n#### Solution\n\n1.  State the random variables and the parameters in words\n\n$x_1:$ survival time of patient with Stomach cancer\n\n$x_2:$ survival time of patient with Bronchus (lung) cancer\n\n$x_3:$ survival time of patient with Colon cancer\n\n$x_4:$ survival time of patient with Ovarian cancer\n\n$x_5:$ survival time of patient with Breast cancer\n\n$\\mu_1:$ mean survival time of patient with Stomach cancer\n\n$\\mu_2:$ mean survival time of patient with Bronchus (lung) cancer\n\n$\\mu_3:$ mean survival time of patient with Colon cancer\n\n$\\mu_4:$ mean survival time of patient with Ovarian cancer\n\n$\\mu_5:$ mean survival time of patient with Brest cancer\n\nNow before conducting the hypothesis test, look at the means and standard deviations. There appears to be a difference between at least two of the means, but realize that the standard deviations are very different. The difference you see may not be significant.\n\nNotice the sample sizes are not the same.\n\n2.  State the null and alternative hypotheses and the level of significance\n\n$H_o:$ all the means are equal\n\n$H_a:$ some of the means are different\n\n$\\alpha=0.01$\n\n3.  State and check the conditions for the hypothesis test\n\n<!-- -->\n\na.  A random sample of 13 survival times from stomach cancer was taken. A random sample of 17 survival times from bronchus cancer was taken. A random sample of 17 survival times from colon cancer was taken. A random sample of 6 survival times from ovarian cancer was taken. A random sample of 11 survival times from breast cancer was taken.\n\n    check: These statements may not be true. This information was not shared as to whether the samples were random or not but it may be safe to assume that.\n\nb.  The samples are all independent.\n\n    check: Since the individuals have different cancers, then the samples are independent.\n\nc.  Population of all survival times from stomach cancer is normally distributed. Population of all survival times from bronchus cancer is normally distributed. Population of all survival times from colon cancer is normally distributed. Population of all survival times from ovarian cancer is normally distributed. Population of all survival times from breast cancer is normally distributed.\n\n    check: Looking at the density plots and normal quantile plots for each sample, it appears that none of the populations are normally distributed. The sample sizes are somewhat different for the problem. This condition may not be true.\n\n    (ref:cancer-density--graphs-cap) Density Plot of Survival Times for Different Cancers\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    gf_density(~survival|organ, data=Cancer, title=\"Survival times for Different Cancers\", xlab = \"Survival Times\")\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    ```\n    Warning: `stat(density)` was deprecated in ggplot2 3.4.0.\n    ℹ Please use `after_stat(density)` instead.\n    ```\n    :::\n    \n    ::: {.cell-output-display}\n    ![(ref:cancer-density-graphs-cap)](Chi-Square-ANOVA-Tests_files/figure-docx/cancer-density-graphs-1.png){fig-alt='Density plots of survival times for diffent cancers. All appear right skewed'}\n    :::\n    :::\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    gf_qq(~survival|organ, data=Cancer, title=\"Survival times for Different Cancers\")\n    ```\n    \n    ::: {.cell-output-display}\n    ![](Chi-Square-ANOVA-Tests_files/figure-docx/cancer_qq_graphs-1.png){fig-alt='Quantile plots of survival times for diffent cancers. All do appear exponential'}\n    :::\n    :::\n\n\nd.  The population variances are all equal.\n\n    check: The sample standard deviations are approximately 346.3, 209.9, 427.2, 1098.6, and 1239.0 respectively. This condition does not appear to be met, since the sample standard deviations are very different. The sample sizes are somewhat different for the problem. This condition may not be true.\n\n4\\. Find the test statistic and p-value\n\nTo find the test statistic and p-value on r Studio, the commands would be:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults=aov(survival~organ, data=Cancer) \nsummary(results)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df   Sum Sq Mean Sq F value   Pr(>F)    \norgan        4 11535761 2883940   6.433 0.000229 ***\nResiduals   59 26448144  448274                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe test statistic is F = 6.433 and the p-value = 0.000229.\n\n5.  Conclusion\n\nReject $H_o:$ since the p-value is less than 0.01.\n\n6.  Interpretation\n\nThere is enough evidence to support that at least two of the mean survival times from different cancers are not equal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_stats(survival~organ, data=Cancer, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  response    organ      mean\n1 survival   Breast 1395.9091\n2 survival Bronchus  211.5882\n3 survival    Colon  457.4118\n4 survival    Ovary  884.3333\n5 survival  Stomach  286.0000\n```\n:::\n:::\n\n\nBy examination of the means, it appears that the mean survival time for breast cancer is different from the mean survival times for both stomach and bronchus cancers. It may also be different for the mean survival time for colon cancer. The others may not be different enough to actually say for sure.\n\n### Homework\n\n**In each problem show all steps of the hypothesis test. If some of the conditions are not met, note that the results of the test may not be correct and then continue the process of the hypothesis test.**\n\n1.  Cuckoo birds are in the habit of laying their eggs in other birds' nest. The other birds adopt and hatch the eggs. The lengths (in cm) of cuckoo birds' eggs in the other species nests were measured and are in table #11.3.2 (\"Cuckoo eggs in,\" 2013). Do the data show that the mean length of cuckoo bird's eggs is not all the same when put into different nests? Test at the 5% level.\n\n##### Table #11.3.2: Lengths of Cuckoo Bird Eggs in Different Species Nests\n\n\n::: {.cell}\n\n```{.r .cell-code}\nEggs <- read.csv( \"https://krkozak.github.io/MAT160/Birds_eggs.csv\") \nhead(Eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  length   bird\n1  19.65 Meadow\n2  20.05 Meadow\n3  20.65 Meadow\n4  20.85 Meadow\n5  21.65 Meadow\n6  21.65 Meadow\n```\n:::\n:::\n\n\n###### Code book for data frame Eggs\n\nDescription Cuckoo birds are in the habit of laying their eggs in other birds' nest. The other birds adopt and hatch the eggs. The lengths (in cm) of cuckoo birds' eggs in the other species nests were measured\n\nThis data frame contains the following columns:\n\nlength: length of cuckoo bird's eggs in other species nets (cm)\n\nbird: bids where eggs were found in their nests. The birds are Meadow Pipit, Tree Pipit, Hedge Sparrow, Robin, Pied Wagtail, and Wren\n\nSource Cuckoo eggs in nest of other birds. (2013, December 04). Retrieved from \\<http://lib.stat.cmu.edu/DASL/Stories/cuckoo.html\\>\n\nReferences SOCR Home page: \\<http://www.socr.ucla.edu\\>\n\n2.  Levi-Strauss Co manufactures clothing. The quality control department measures weekly values of different suppliers for the percentage difference of waste between the layout on the computer and the actual waste when the clothing is made (called run-up). The data is in table #11.3.3, (\"Waste run up,\" 2013). Do the data show that there is a difference between some of the suppliers? Test at the 1% level.\n\n##### Table #11.3.3: Run-ups for Different Plants Making Levi Strauss Clothing\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLevi <- read.csv( \"https://krkozak.github.io/MAT160/Levi_jeans.csv\") \nhead(Levi) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  run_up   plant\n1    1.2 Plant_1\n2   10.1 Plant_1\n3   -2.0 Plant_1\n4    1.5 Plant_1\n5   -3.0 Plant_1\n6   -0.7 Plant_1\n```\n:::\n:::\n\n\n###### Code book for data frame Levi\n\nDescription Levi-Strauss Co manufactures clothing. The quality control department measures weekly values of different suppliers for the percentage difference of waste between the layout on the computer and the actual waste when the clothing is made (called run-up).\n\nThis data frame contains the following columns:\n\nrun_up: percentage difference of waste between the layout on the computer and the actual waste when the clothing is made. There are some negative values because sometimes the supplier is able to layout the pattern better than the computer\n\nplant: Which suppliers\n\nSource Waste run up. (2013, December 04). Retrieved from \\<http://lib.stat.cmu.edu/DASL/Stories/wasterunup.html\\>\n\nReferences \\<http://lib.stat.cmu.edu/DASL\\>\n\n3.  Several magazines were grouped into three categories based on what level of education of their readers the magazines are geared towards: high, medium, or low level. Then random samples of the magazines were selected to determine the number of three-plus-syllable words were in the advertising copy, and the data is in table #11.3.4 (\"Magazine ads readability,\" 2013). Is there enough evidence to show that the mean number of three-plus-syllable words in advertising copy is different for at least two of the education levels? Test at the 5% level.\n\n##### Table #11.3.4: Number of Three Plus Syllable Words in Advertising Copy\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAdvertising <- read.csv( \"https://krkozak.github.io/MAT160/three_syllable_words.csv\") \nhead(Advertising) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  number education\n1     34      High\n2     21      High\n3     37      High\n4     31      High\n5     10      High\n6     24      High\n```\n:::\n:::\n\n\n###### Code book for data frame Advertising\n\nDescription Several magazines were grouped into three categories based on what level of education of their readers the magazines are geared towards: high, medium, or low level. Then random samples of the magazines were selected to determine the number of three-plus-syllable words were in the advertising copy\n\nThis data frame contains the following columns:\n\nnumber: number of three=plus-syllable words in advertising copy\n\neducation: level of education the magazine is geared towards: high, medium, or low\n\nSource Magazine ads readability. (2013, December 04). Retrieved from \\<http://lib.stat.cmu.edu/DASL/Datafiles/magadsdat.html\\>\n\nReferences \\<http://lib.stat.cmu.edu/DASL\\>\n\n4.  A study was undertaken to see how accurate food labeling for calories on food that is considered reduced calorie. The group measured the amount of calories for each item of food and then found the percent difference between measured and labeled food. The group also looked at food that was nationally advertised, regionally distributed, or locally prepared. The data is in table #11.3.5 (\"Calories datafile,\" 2013). Do the data indicate that at least two of the mean percent differences between the three groups are different? Test at the 5% level.\n\n##### Table #11.3.5: Percent Differences Between Measured and Labeled Food\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFood <- read.csv( \"https://krkozak.github.io/MAT160/Food_calories_percent_diff.csv\") \nhead(Food)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  percent_diff     food\n1            2 national\n2          -28 national\n3           -6 national\n4            8 national\n5            6 national\n6           -1 national\n```\n:::\n:::\n\n\n###### Code book for data frame Food\n\nDescription A study was undertaken to see how accurate food labeling for calories on food that is considered reduced calorie. The group measured the amount of calories for each item of food and then found the percent difference between measured and labeled food. The group also looked at food that was nationally advertised, regionally distributed, or locally prepared.\n\nThis data frame contains the following columns:\n\npercent_diff: percent difference between the number of calories that are measured in the food and the amount that is labeled on the food.\n\nfood: Where the food is created: nationally advertised, regionally distributed, or locally prepared.\n\nSource Calories datafile. (2013, December 07). Retrieved from \\<http://lib.stat.cmu.edu/DASL/Datafiles/Calories.html\\>\n\nReferences \\<http://lib.stat.cmu.edu/DASL\\>\n\n5.  The amount of sodium (in mg) in different types of hot dogs is in table #11.3.6 (\"Hot dogs story,\" 2013). Is there sufficient evidence to show that the mean amount of sodium in the types of hot dogs are not all equal? Test at the 5% level.\n\n##### Table #11.3.6: Amount of Sodium (in mg) in Beef, Meat, and Poultry Hotdogs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHotdog_complete <-read.csv( \"https://krkozak.github.io/MAT160/Hot_Dog_all_Dataset.csv\") \nhead(Hotdog_complete) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  type calories sodium\n1 Beef      186    495\n2 Beef      181    477\n3 Beef      176    425\n4 Beef      149    322\n5 Beef      184    482\n6 Beef      190    587\n```\n:::\n:::\n\n\n###### Code book for data frame Hotdog\n\nDescription Results of a laboratory analysis of calories and sodium content of major hot dog brands. Researchers for Consumer Reports analyzed three types of hot dog: beef, poultry, and meat (mostly pork and beef, but up to 15% poultry meat).\n\nThis data frame contains the following columns:\n\ntype: Type of hot dog (beef or poultry or meat (mostly pork and beef but up to 15% poultry meat))\n\ncalories: Calories per hot dog\n\nsodium: Milligrams of sodium per hot dog\n\nSource SOCR 012708 id data hot dogs. (2013, November 13). Retrieved from \\<http://wiki.stat.ucla.edu/socr/index.php/SOCR_012708_ID_Data_HotDogs\\>\n\nReferences SOCR Home page: \\<http://www.socr.ucla.edu\\>\n",
    "supporting": [
      "Chi-Square-ANOVA-Tests_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}