---
title: "Numerical Description of Data"
format: html
editor: visual
---

```{r setup3, include=FALSE}
library("mosaic") 
library("MASS")
```

**Before you begin, Click to expand the box below to review the process for importing a dataset.**

::: {#Importing-cats-to-Rguroo .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'}  Importing Data to Rguroo"} 

1. Open the **Data** toolbox in Rguroo.  
2. From the [Data Import]{.dpd} dropdown, select [Dataset Repository]{.fun}.  
3. In the top search box, type [kozak]{.typein}, then select the [Statistics Using Technology – Kozak]{.repo} repository.  
4. In the middle search box, type the first few letters of the dataset name, and choose your desired dataset name that appears in the lower panel.  
5. Click the [Import]{.button}. The dataset will be imported to your Rguroo account.
6. Click [Close]{.button} to exit the dialog.  
7. To view the dataset, double-click the dataset name under the **Data** toolbox list.

:::

Chapter 1 discussed what a population, sample, parameter, and statistic are, as well as how to take different types of samples. Chapter 2 discussed ways to graphically display data. There was also a discussion of important characteristics: center, variations, distribution, outliers, and changing characteristics of the data over time. Distributions and outliers can be identified using graphical means. Finding the center and variation can be done using numerical methods that will be discussed in this chapter. Both graphical and numerical methods are part of a branch of statistics known as **descriptive statistics**. Later, descriptive statistics will be used to make decisions and/or estimate population parameters using methods that are part of the branch called **inferential statistics**.

## Measures of Center

This section focuses on measures of central tendency. Many times you are asking what to expect on average. For example, when you pick a major, you would probably ask how much you can expect to earn in that field. If you are thinking of relocating to a new town, you might ask how much you can expect to pay for housing. If you are planting vegetables in the spring, you might want to know how long it will be until you can harvest. These questions, and many more, can be answered by knowing the center of the data. There are three measures of the "center" of the data: the mode, median, and mean. Any of the values can be referred to as an "average."

The **mode** is the data value that occurs most frequently in the data. To find it, you count how often each data value occurs, and then determine which value occurs most often. If there is a tie between two values for the most number of times, then both values are the mode and the data are called bimodal (two modes). If every data value occurs the same number of times, there is no mode. If there are more than two values that appear the most times, then usually there is no mode. The mode is not always a useful measure of center, especially when a dataset has more than one mode.

The **median** is the data value in the middle of a sorted list of data. To find the median, you arrange the data in order and then determine which value is in the middle of the data values.

The **mean** is the arithmetic average of the numbers. The mean, median, and mode are all measures of center, although the word 'average' is most commonly used to refer to the mean.

In this course, we work primarily with numerical data (interval and ratio), so our focus will be on the mean and median as measures of center. The mode is more commonly used with categorical data, where it identifies the most frequently occurring category. While the mean and median both require numerical values, the key difference is that the mean uses every data value in its calculation, making it sensitive to extreme values, whereas the median depends only on the position of the middle value.

### Population Mean and Sample Mean

Because the mean is used extensively in statistics, it has special notation that distinguishes between a population and a sample. The **population mean**, denoted by the Greek letter $\mu$ (pronounced ``mu"), represents the true average of an entire population. It is calculated using the formula $\mu=\frac{\sum{x}}{N}$, where $N$ is the total number of values in the population, $x$ represents each individual data value, and $\sum{x}$ means to add up all the data values. In practice, we rarely know the population mean because we typically cannot collect data from every member of a population.

Instead, we work with samples and calculate the **sample mean**, denoted by $\bar{x}$ (pronounced ``x-bar"). The sample mean uses the same calculation process as the population mean but with different notation: $\bar{x}=\frac{\sum{x}}{n}$, where $n$ is the number of values in the sample. Notice that we use a lowercase $n$ for sample size and an uppercase $N$ for population size. The sample mean $\bar{x}$ serves as our best estimate of the unknown population mean $\mu$. This relationship between sample statistics and population parameters is fundamental to inferential statistics -- we use what we observe in a sample to make informed conclusions about the larger population.



::: {#exm-mean-median-cats}
## Finding the Mean and Median Using Rguroo

Suppose a vet wants to find the average weight of cats. The weights (in kg) of 144 cats are  given in a dataset named [cats]{.data}. Find the mean and median of the weight of a cat. 

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.

:::

```{r cats5-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of cats dataset"
#| label: tbl-Cats
#| tbl-cap: "Head of Cats"
knitr::kable(head(cats))
```




**Solution**


Looking at the dataset for cats weights, @tbl-Cats, you see that there are several variables. A Code Book describes the dataset, explains what the variables are including the units, and the source of the dataset. The code book for the [cats]{.data} is below.

::: {#code-book-cats .callout-tip .codebook collapse="true"}
## Code book for cats Dataset

![Code book for cats dataset](code_book_cats.jpg){fig-alt="Code book cats Dataframe"}
:::

Before starting any mathematics problem, it is always a good idea to define the unknown in the problem. In statistics, you want to define the variable. The symbol for the variable is $x$.

The variable is $x$ = weight of a cat

Click to expand the box below to see how to calculate the mean and median in Rguroo.

:::: {#Calculating-summary-stats-in-Rguroo .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Calculating the Mean and Median Weight of Cats"}

**Before you begin:** Make sure you have already imported the [cats]{.data} dataset into your **Data** Toolbox, as was shown [here](#Importing-cats-to-Rguroo).

1.  Open the **Data** toolbox.\
2.  Click on the [Functions]{.dpd} dropdown, and select [Summary Statistic]{.fun}. This opens the [Basic Summary Statistic]{.dialog}.\
3.  From the [Dataset]{.dpd} dropdown, select the [cats]{.data} dataset.\
4.  From the [Numerical]{.dpd} dropdown, select the [Bwt]{.var} variable. \
5.  In the **Statistics** section of the dialog, select the checkbox for [Mean]{.des} and [Median]{.des}.\
6.  Click the preview icon ![preview icon](Rguroo_Icons/preview_inline.png) to see the summary statistics which is shown in @fig-summary-cats.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog"}
![Basic Summary Statistic dialog in Rguroo](Rguroo_dialogs/Numerical_description/summary_stat_dia_clean.png){width="500px"}
:::
::::

```{r,echo=FALSE}
#| fig-alt: "Mean and Median Output from Rguroo"
#| warning: FALSE
#| label: fig-summary-cats
#| fig-cap: "Mean and Median Weight of Cats"
#| out-width: "80%"
knitr::include_graphics("Rguroo_outputs/Numerical_Description/cats_summary_output.png")
```



The mean weight is 2.72 kg.


```{r statistics-cats3, echo = FALSE, eval = FALSE}
#df_stats(~Bwt, cats, median)
```

The median weight is 2.7 kg also. It appears the average weight of all cats in this dataset is 2.7 kg.

::: {#exm-mean-median-cats-factor}
## Finding Mean and Median with Factor

Suppose you want to know if male cats weigh more than female cats. Looking at the variables, you notice that there is a variable for the sex of the cat. You can look at the weights of males and females separately.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.
:::

**Solution**

Click to expand the box below to see how to calculate the mean and median, separated by sex, in Rguroo.

:::: {.callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Calculating the Mean and Median Weight of Cats by Sex"}
**Before you begin:** Make sure you have already imported the [cats]{.data} dataset into your **Data** Toolbox, as was shown [here](#Importing-cats-to-Rguroo).

1.  Open the **Data** toolbox.\
2.  Click on the [Functions]{.dpd} dropdown, and select [Summary Statistic]{.fun}. This opens the Basic Summary Statistic dialog.\
3.  From the [Dataset]{.dpd} dropdown, select the [cats]{.data} dataset.\
4.  From the [Numerical]{.dpd} dropdown, select the [Bwt]{.var} variable.
5.  From the [Factor 1]{.dpd} dropdown, select the [Sex]{.des} factor.
6.  In the **Statistics** section of the dialog, select the checkbox for [Mean]{.des} and [Median]{.des}.\
7.  Click the preview icon ![preview icon](Rguroo_Icons/preview_inline.png) to see the summary statistics.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog"}
![Basic Summary Statistic dialog in Rguroo](Rguroo_dialogs/Numerical_Description/cats_weight_sex.png){width="500px"}
:::
::::

```{r,echo=FALSE}
#| fig-alt: "Mean and Median by Sex Output from Rguroo"
#| warning: FALSE
#| label: fig-factor-summary-cats
#| fig-cap: "Mean and Median Weight of Cats by Sex"
#| out-width: "80%"
knitr::include_graphics("Rguroo_outputs/Numerical_Description/cat_wt_sex_output.png")
```

```{r statistics-cats-sex2, echo = FALSE, eval = FALSE}
#df_stats(Bwt~Sex, data=cats, mean, median)
```

Notice that the female cats' mean weight is 2.36 kg and the male cats' mean weight is 2.9 kg. The median weight of female cats is 2.3 kg and for males it is 2.9 kg. So it does appear that male cats weigh a bit more than the female cats.

There are many different summary statistics that can be found. An example is the minimum and maximum value. In the next example, you will see how to find the min and max values and then filter them out of a dataset to see what effect they have on the mean and median.

::: {#exm-effect-extreme-values}
## Effect of Extreme Values on Mean and Median

Find the minimum and maximum values of cats weights.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.
:::

**Solution**

The steps to find the minimum and the maximum in Rguroo are similar to finding the mean and median described [here](#Calculating-summary-stats-in-Rguroo). In the **Statistics** section of the dialog, select the checkbox for [Minimum]{.des} and [Maximum]{.des}.

@fig-max-min-cats shows the Basic Summary Statistic Dialog and Output from Rguroo for the minimum and maximum of cats body weight.

```{r,echo=FALSE}
#| fig-alt: "Dialog and Output from Rguroo for Maximum and Minimum"
#| warning: FALSE
#| label: fig-max-min-cats
#| fig-cap: "Maximum and Minimum Weight of Cats"
#| fig-subcap: 
#|   - "Dialog box"
#|   - "Output results"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_Description/max_min_dialog.png",
"Rguroo_outputs/Numerical_Description/max_min_output.png"))
```

```{r statistics-cats4, echo = FALSE, evaluate = FALSE}
#df_stats(~Bwt, data=cats, min, max)
```

The minimum weight of a cat in this dataset is 2 kg and the maximum weight of a cat is 3.9 kg.

You can create two new datasets in Rguroo by subsetting (filtering). One dataset will exclude the maximum value and include values less than 3.9, and the other will exclude the minimum value and include values greater than 2.

Click to expand the box below to see how to obtain a subset of the [cats]{.data} dataset in Rguroo that includes values less than 3.9 kg.

:::: {#Subsetting-Data-in-Rguroo .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Subsetting the cats Dataset"}
**Before you begin:** Make sure you have already imported the [cats]{.data} dataset into your **Data** Toolbox, as was shown [here](#Importing-cats-to-Rguroo).

1.  Open the **Data** toolbox.\
2.  Click on the [Functions]{.dpd} dropdown, and select [Subset]{.fun}. This opens the [Data Subset]{.dialog} dialog.\
3.  From the [Dataset]{.dpd} dropdown, select the [cats]{.data} dataset.\
4.  Select the [Logical Expression]{.button} button.\
5.  To create a new Logical Expression, click the green plus icon ![plus icon](Rguroo_Icons/add.png).
6.  From the [Variable]{.dpd} dropdown, select the [Bwt]{.var}. From the [Op.]{.dpd} (operations) dropwdown, select the less than symbol (\<). In the Value column, enter 3.9 (the maximum body weight of cats dataset). Click the [Done]{.button}.
7.  Click the preview icon ![preview icon](Rguroo_Icons/preview_inline.png) to see a preview of the filtered data.
8.  In Save As... textbox, name the new dataset [cats_nomax]{.typein} and click the [Save As...]{.button} button.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog"}
 ![Data Subset Dialog in Rguroo](Rguroo_dialogs/Numerical_description/logical_subset_nomax.png){width="500px"} ![Logical Expression Dialog in Rguroo](Rguroo_dialogs/Numerical_description/subset_nomax_cats.png){width="500px"} ![Save As... Dataset View](Rguroo_outputs/Numerical_Description/save_data_nomax.png)
:::
::::


Then create a dataset that excludes the minimum value using the same steps shown [here](#Subsetting-Data-in-Rguroo), except in the [Logical Expression]{.dialog} dialog, choose the greater than (\>) operator in the [Op.]{.dpd} dropdown and enter 2 in the Value column, as shown in @fig-min-cats. Save this new dataset as [cats_nomin]{.data}.

```{r,echo=FALSE}
#| fig-alt: "Logical Expression Dialogfor removing the minimum"
#| warning: FALSE
#| label: fig-min-cats
#| fig-cap: "Logical Expression Dialog for Removing the Minimum Weight of Cats"
#| out-width: "80%"
knitr::include_graphics(
  "Rguroo_dialogs/Numerical_Description/min_dialog.png"
)
```




Now you can find the mean and median of each new dataset using the steps described [here](#Calculating-summary-stats-in-Rguroo) using the new datasets [cats_nomax]{.data} and [cats_nomin]{.data}.

The mean without the maximum value is 2.70 kg, and the median is 2.7 kg.

The mean without the minimum value is 2.75 kg, and the median is 2.7 kg.

From the effect of extremes [example](#exm-effect-extreme-values), the mean of the [cats]{.data} dataset with all the values is 2.72 kg, while the median is 2.7 kg. Notice that when the maximum value was excluded from the dataset, the mean decreased slightly but the median did not change, and when the minimum value was excluded from the dataset, the mean increased a little but the median did not change. This shows that the mean is affected by extreme values, while the median is not. We say the median is a resistant measure of center because it is not affected by extreme values as much.

An **extreme value** is a data value that is much higher or much lower than the rest of the data. When extreme values are present, the median is generally a better measure of center than the mean because the median is not pulled by those values. When there are no extreme values, the mean and median tend to be similar, and the mean is commonly used. This is because the mean is **not resistant** — it is affected by extreme values, which can pull it higher or lower. The median, on the other hand, is **resistant** — it remains stable even when extreme values are present in the data.

Later in this chapter, you will learn a formal method for determining whether an extreme value qualifies as an **outlier** — a data point that falls far enough from the rest of the data to be flagged as unusual.

You need to be aware that people generally choose the measure of center that best supports their claim. When you read an article in the newspaper and it talks about the "average" it usually means the mean but sometimes it refers to the median. Some articles will use the word "median" instead of "average" to be more specific. If you need to make an important decision and the information says "average", it would be wise to ask if the "average" is the mean or the median before you decide.

As an example, suppose that a company wants to report the mean salary as the average salary for the company. The high salaries of the administrators will pull the mean upward, making the average appear higher. The company can then say that employees are paid well because the average is high. However, the employees would prefer to use the median since it is not affected as much by the extreme administrative salaries and gives a lower measure of center. This makes the salaries appear lower and suggests that a raise is in order.


Why use the mean instead of the median? Imagine repeatedly taking different samples from the same population. Some samples may include more large values, while others may include more small values. When we calculate the mean for each sample, some sample means will overestimate the true center of the population and others will underestimate it. Over many samples, these overestimates and underestimates tend to balance out. The median, however, can tend to underestimate or overestimate the center more often in one direction, depending on how the middle values fall in the samples. Because of this, the mean does not systematically overestimate or underestimate the center of the population, making it a reliable measure of center.


To understand how different measures of center relate to skewed or symmetric distributions, see @fig-centers-dist. For a left-skewed distribution, the mean is smaller than the median. For a right-skewed distribution, the mean is larger than the median. For a symmetric distribution, the mean and the median are the same.


```{r,echo=FALSE}
#| fig-alt: "skewed left graph with mean, median,mode lines, then symmetric graph with all three the same line, then skewed right graph with mode, median, mean lines"
#| warning: FALSE
#| label: fig-centers-dist
#| fig-cap: "Mean, median, mode as related to distribution"
#| out-width: "80%"
knitr::include_graphics("images/centers_distribution_new.png")
```

### Weighted Average

Another type of average is a weighted average. Weighted averages are commonly used in situations where some components matter more than others. For example, a teacher may use a weighted average when calculating a student's final course grade. Homework, quizzes, and exams may all contribute to the final grade, but exams might count more because they measure overall understanding more directly. In this case, exams are given more weight than homework, so they have a larger impact on the final grade. Similarly, employers may use weighted averages in performance evaluations when some aspects of a job are more important than others.

As an example, a full-time teacher at a community college may be evaluated on their service to the college, their service to the community, whether their paperwork is turned in on time, and their teaching. However, teaching is much more important than whether their paperwork is turned in on time. When the evaluation is completed, more weight needs to be given to the teaching and less to the paperwork. This is a weighted average.

To calculate a weighted average, each data value is multiplied by its weight (the number representing its importance), then these products are added together. Finally, this sum is divided by the total of all the weights. The formula captures this process:

$\text{weighted average}=\frac{\sum{x \cdot w}}{\sum{w}}$

where $x$ represents each data value and $w$ represents the weight (or importance) assigned to that value.

::: {#exm-weighted-average}
## Calculating Weighted Average

In your biology class, your final grade is based on several components: a lab score, scores on two major tests, and your score on the final exam. Each component is graded out of 100 points. The lab score is worth 15% of the course grade, the two exams are worth 25% each, and the final exam is worth 35% of the course. Suppose you earned scores of 95 on the labs, 83 and 76 on the two exams, and 84 on the final exam. Compute your weighted average for the course.
:::

**Solution**

Variable: $x$ = score

A weighted average can be found using Rguroo. First, we will create a new dataset in Rguroo. Click to expand the box below to see how to create a new dataset in Rguroo:

:::: {#Creating-new-dataset .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Creating a New Dataset"}
1.  Open the **Data** toolbox.\
2.  Click on the [Data Import]{.dpd} dropdown, and select [Create New Dataset]{.fun}. This opens the [Create New Dataset]{.dialog} dialog. Specify the number of rows and columns  for your new dataset (optional), and click the [Create Dataset]{.button} button. This opens Rguroo's dataset editor.\
3.  The default variable names will be [Var1]{.var}, [Var2]{.var}, etc. To change the variable name, move your cursor over the variable name in the column header. You will see the Variable Context Menu icon ![variable context menu icon](Rguroo_Icons/four_horizontal_line_icon.png). Click on the icon to open the variable context menu. 
4. From the variable context menu select the option [Rename]{.des}. This will bring up the [Rename Variable]{.dialog} dialog box. In the dialog box, type in the new name for your variable and press enter. The new name will appear in the column header. Note that variable names cannot have spaces. For this example we have two variables; specify the names [score]{.var} and [weight]{.var} in two columns.\
5.  Enter your data in the two columns.\
6.  Enter a name for your dataset in the [Save As]{.des} textbox on the top, and click the [Save as]{.button} button to save your dataset. For this example, name the dataset [biology_grade]{.data}.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog and new dataset"}
![New Dataset Dialog](Rguroo_dialogs/Numerical_description/new_dataset_dialog.png){width="500px"} ![Biology Class Dataset](Rguroo_outputs/Numerical_Description/biology_dataset.png){width="500px"}
:::
::::


To calculate the weighted average in Rguroo, you will follow similar steps as described [here](#Calculating-summary-stats-in-Rguroo). In the [Basic Summary Statistics]{.dialog} dialog box select the [biology_grade]{.data} from the [dataset]{.dpd} dropdown, select [score]{.var} in the [Numerical]{.dpd} dropdown, and select [weight]{.var} in the [frequency]{.dpd} dropdown as shown in figure @fig-weighted-mean.

```{r,echo=FALSE}
#| fig-alt: "basic summary statistics dialog box and weighted mean output"
#| warning: FALSE
#| label: fig-weighted-mean
#| fig-cap: "Weighted Mean of Biology Grade"
#| fig-subcap: 
#|   - "Basic Summary Statistics Dialog box"
#|   - "Output results"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_Description/summary_stat_dialog_weight_mean.png",
"Rguroo_outputs/Numerical_Description/weight_mean_bio_grade.png"))
```


Your weighted mean in the biology class is 83.4%. Using the traditional grading scale, you have a B in the class.


::: {#exm-weighted-average-faculty-ratings}
## Calculating Weighted Averages

The faculty evaluation process at John Jingle University rates a faculty member on the following activities: teaching, publishing, committee service, community service, and submitting paperwork in a timely manner. The process involves reviewing student evaluations, peer evaluations, and supervisor evaluation for each teacher and awarding him/her a score on a scale from 1 to 10 (with 10 being the best). The weights for each activity are 20 for teaching, 18 for publishing, 6 for committee service, 4 for community service, and 2 for paperwork.

a)  One faculty member had the following ratings: 8 for teaching, 9 for publishing, 2 for committee work, 1 for community service, and 8 for paperwork. Compute the weighted average of the evaluation.
b)  Another faculty member had ratings of 6 for teaching, 8 for publishing, 9 for committee work, 10 for community service, and 10 for paperwork. Compute the weighted average of the evaluation.
c)  Which faculty member had the higher average evaluation?
:::

**Solution**

a)  Variable: $x$ = rating, $w$ = weight



To find the weighted average using Rguroo, start by creating a new dataset as described [here](#Creating-new-dataset). The new dataset, including weights and scores for each faculty, is shown in the figure @fig-dataset-ratings below.

```{r,echo=FALSE}
#| fig-alt: "new dataset for weight of category in a and b"
#| warning: FALSE
#| label: fig-dataset-ratings
#| fig-cap: "Faculty Ratings Dataset"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_outputs/Numerical_Description/ex_4_1_8_dataset.png"))
```

Calculate the weighted average in Rguroo using the same steps described [here](#Calculating-summary-stats-in-Rguroo). In the [Basic Summary Statistics]{.dialog} dialog box select the [faculty_ratings]{.data} from the [dataset]{.dpd} dropdown, select [faculty_a]{.var} in the [Numerical]{.dpd} dropdown, and select [weight]{.var} in the [frequency]{.dpd} dropdown as shown in figure @fig-faculty_a-weighted_mean.

```{r,echo=FALSE}
#| fig-alt: "basic summary statistics dialog box and weighted mean output faculty_a"
#| warning: FALSE
#| label: fig-faculty_a-weighted_mean
#| fig-cap: "Weighted Mean of Faculty Ratings"
#| fig-subcap: 
#|   - "Basic Summary Statistics Dialog box"
#|   - "Output results"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_Description/ex_4_1_8_a_dialog.png",
"Rguroo_outputs/Numerical_Description/ex_4_1_8_a_output.png"))
```

The weighted average is 7.08.

b) The weighted mean can be calculated in the same fashion as part (a). In the [Basic Summary Statistics]{.dialog} dialog box select the [faculty_ratings]{.data} from the [dataset]{.dpd} dropdown, select [faculty_b]{.var} in the [Numerical]{.dpd} dropdown, and select [weight]{.var} in the [frequency]{.dpd} dropdown as shown in figure @fig-faculty_b-weighted_mean.

```{r,echo=FALSE}
#| fig-alt: "basic summary statistics dialog box and weighted mean output faculty_b"
#| warning: FALSE
#| label: fig-faculty_b-weighted_mean
#| fig-cap: "Weighted Mean of Faculty Ratings"
#| fig-subcap: 
#|   - "Basic Summary Statistics Dialog box"
#|   - "Output results"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_Description/ex_4_1_8_b_dialog.png",
"Rguroo_outputs/Numerical_Description/ex_4_1_8_b_output.png"))
```

The weighted average for this employee is 7.56.

c)  Which faculty member had the higher average evaluation?

    The second faculty member has a higher average evaluation.

### Homework for Measures of Center Section

**Use Rguroo on all problems. State the variable on all problems.**

1.  Cholesterol levels were collected from patients a certain number of days after they had a heart attack and the first six rows of the data are shown in @tbl-Cholesterol. Find the mean and median for cholesterol levels 2 days after the heart attack.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cholesterol]{.data}.
:::

```{r,echo=FALSE}
#| fig-alt: "Repository search"
#| warning: FALSE
#| label: fig-kozak-repo
#| fig-cap: "Repository Search Dialog"
#| out-width: "80%"
knitr::include_graphics("Rguroo_dialogs/Numerical_Description/chol_data_repo.png")
```

```{r cholesterol2-data,echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Cholesterol dataset"
#| label: tbl-Cholesterol
#| tbl-cap: "Head of Cholesterol Levels of Patients After Heart Attack"
Cholesterol<-read.csv( "https://krkozak.github.io/MAT160/cholesterol.csv") 
knitr::kable(head(Cholesterol))
```

::: {#code-book-cholesterol .callout-tip .codebook collapse="true"}
## Code book for Cholesterol Dataset

**Description** A study was conducted at a major north eastern American medical centre regarding blood cholesterol levels and heart-attack incidents. A total of 28 heart-attack patients had their cholesterol levels measured two days, 4 days, and 14 days after the attack. In addition, cholesterol levels were recorded for a control group of 30 people who had not had a heart attack. The units of cholesterol measurement are not given in the original reference but are presumably mg/dL of blood.

This dataset contains the following columns:

[Patient]{.var}: Patient number

[day2]{.var}: Cholesterol level of patient 2 days after heart attack. (mg/dL)

[day4]{.var}: Cholesterol level of patient 4 days after heart attack. (mg/dL)

[day14]{.var}: Cholesterol level of patient 14 days after heart attack. (mg/dL)

[Source](https://gksmyth.github.io/ozdasl/general/cholest.html) Ryan, B. F., Joiner, B. L., & Ryan, Jr, T. A. (1985). Cholesterol levels after heart attack.

References Ryan, Joiner & Ryan, Jr, 1985
:::

2.  The lengths (in kilometers) of rivers on the South Island of New Zealand and what body of water they flow into are given in a dataset named [length]{.data}. The first six rows of this dataset are listed in @tbl-Length (Lee, 1994). Find the mean and median length of rivers that flow into the Pacific Ocean and the mean and median length of rivers that flow into the Tasman Sea.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [length]{.data}.
:::

```{r length2-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Length dataset"
#| label: tbl-Length
#| tbl-cap: "Head of Length of New zealand rivers (km)"
Length<-read.csv( "https://krkozak.github.io/MAT160/length.csv") 
knitr::kable(head(Length))
```

::: {#code-book-length .callout-tip .codebook collapse="true"}
## Code book for Length Dataset

**Description** The data records the length of rivers in the South Island of New Zealand. The lengths are given in kilometres. The second variable, FlowsInto, indicates whether the river flows into the Pacific Ocean or the Tasman Sea.

This dataset contains the following columns:

[River]{.var}: Name of the river

[length]{.var}: how long the river is in kilometers

[flowsto]{.var}: what body of water the river flows into Pacific Ocean is Pacific and the Tasman Sea is Tasman

[Source](https://gksmyth.github.io/ozdasl/oz/nzrivers.html) Lee, A. (1994). Data analysis: An introduction based on r. Auckland. 

References Lee, A. (1994). Data analysis: An introduction based on r. Auckland.

:::

3.  Print-O-Matic printing company's employees have salaries that are contained in a dataset named [pay]{.data}. The first six rows of these data are given in @tbl-Pay.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [pay]{.data}.
:::

```{r pay2-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Pay dataset"
#| label: tbl-Pay
#| tbl-cap: "Head of Salaries of Print-O-Matic Printing Company Employees"
Pay<-read.csv( "https://krkozak.github.io/MAT160/pay.csv") 
knitr::kable(head(Pay))
```

::: {#code-book-pay .callout-tip .codebook collapse="true"}
## Code book for Pay Dataset

**Description** Salaries of Print-O-Matic printing company's employees

This dataset contains the following columns:

[employee]{.var}:employees position in the company

[salary]{.var}: salary of that employee (Australian dollars (AUD))

Source John Matic provided the data from a company he worked with. The company's name is fictitious, but the data is from an actual company.

References John Matic (2013)

:::

a.  Find the mean and median.

b.  Find the mean and median with the CEOs salaries removed. Hint: You can filter the dataset to remove the CEOs' salaries either by using the Rguroo [Subset]{.fun} function following similar instructions as shown [here](#Subsetting-Data-in-Rguroo) or more simply using the dataset editor as shown below.

:::: {#filter-in-editor .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Filtering the pay Dataset in the Dataset Editor"}
**Before you begin:** Make sure you have already imported the [pay]{.data} dataset into your **Data** Toolbox.

1.  Open the **Data** toolbox.\
2.  Double click on the [pay]{.data} dataset to open it in the dataset editor.\
3.  Click on the filter icon ![filter icon](Rguroo_Icons/filters.png) shown in the right margin of the dataset editor to open the list of variables.\
4.  From the list of variables, click on the [employee]{.var} variable to open the filter dialog for that variable.\
5.  In the filter dialog, uncheck the box for [CEO]{.des} to exclude the CEO from the dataset.\
6.  In Save As... textbox, name the new dataset [pay_no_CEO]{.typein} and click the [Save As...]{.button} button.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Dataset Editor filtering process"}
![Dataset editor showing the filtering function](Rguroo_dialogs/Numerical_description/filter_ceo.png){width="700px"}
:::
::::

c.  What happened to the mean and median when the CEO's salary was removed? Why?

d.  If you were the CEO, who is answering concerns from the union that employees are underpaid, which average (mean or median) of the complete dataset would you prefer? Why?

e.  If you were a platen worker, who believes that the employees need a raise, which average (mean or median) using the complete dataset would you prefer? Why?

4.  Print-O-Matic printing company spends specific amounts on fixed costs every month. These costs are listed in the dataset [cost]{.data}. The first six rows of the data are shown in @tbl-Cost.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cost]{.data}.
:::

```{r cost-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Cost dataset"
#| label: tbl-Cost
#| tbl-cap: "Fixed Costs for Print-O-Matic Printing Company"
Cost<-read.csv( "https://krkozak.github.io/MAT160/cost.csv") 
knitr::kable(head(Cost))
```
::: {#code-book-cost .callout-tip .codebook collapse="true"}
## Code book for Cost Dataset

**Description** fixed monthly charges for Print-0-Matic printing company

This dataset contains the following columns:

[charges]{.var}: Categories of monthly fixed charges

[cost]{.var}: fixed month costs (AUD)

Source John Matic provided the data from a company he worked with. The company's name is fictitious, but the data is from an actual company.

References John Matic (2013)

:::

a.  Find the mean and median.

b.  Find the mean and median with the bank charges removed.

c.  What happened to the mean and median when the bank charges were removed? Why?

d.  If it is your job to oversee the fixed costs, which average (mean or median) using the complete dataset would you prefer to use when submitting a report to administration to show that costs are low? Why?

e.  If it is your job to find places in the budget to reduce costs, which average (mean or median) using the complete dataset would you prefer to use when submitting a report to administration to show that fixed costs need to be reduced? Why?

<!-- -->

5.  Looking at graph 3.1.2, state if the graph is skewed left, skewed right, or symmetric and then state which is larger, the mean or the median?

**Graph 3.1.2: Skewed or Symmetric Graph**

![Graph 3.1.2](/Rguroo_outputs/Numerical_Description/skewed_right_hist.png){fig-alt="histogram with bars on left tallest and then gradually getting shorter as you go to the right"}

6.  Looking at graph 3.1.3, state if the graph is skewed left, skewed right, or symmetric and then state which is larger, the mean or the median?

**Graph 3.1.3: Skewed or Symmetric Graph**

![Graph 3.1.3](Rguroo_outputs/Numerical_Description/skewed_left_hist.png){fig-alt="histogram with bars on left shortest and then gradually getting taller as you go to the right"}

7.  An employee at Coconino Community College (CCC) is evaluated based on goal setting and accomplishments toward the goals, job effectiveness, competencies, and CCC core values. Suppose for a specific employee, goal 1 has a weight of 30%, goal 2 has a weight of 20%, job effectiveness has a weight of 25%, competency 1 has a weight of 4%, competency 2 has a weight of 3%, competency 3 has a weight of 3%, competency 4 has a weight of 3%, competency 5 has a weight of 2%, and core values has a weight of 10%. Suppose the employee has scores of 3.0 for goal 1, 3.0 for goal 2, 2.0 for job effectiveness, 3.0 for competency 1, 2.0 for competency 2, 2.0 for competency 3, 3.0 for competency 4, 4.0 for competency 5, and 3.0 for core values. Find the weighted average score for this employee. If an employee has a score less than 2.5, they must have a Performance Enhancement Plan written. Does this employee need a plan?

8.  An employee at Coconino Community College (CCC) is evaluated based on goal setting and accomplishments toward goals, job effectiveness, competencies, CCC core values. Suppose for a specific employee, goal 1 has a weight of 20%, goal 2 has a weight of 20%, goal 3 has a weight of 10%, job effectiveness has a weight of 25%, competency 1 has a weight of 4%, competency 2 has a weight of 3%, competency 3 has a weight of 3%, competency 4 has a weight of 5%, and core values has a weight of 10%. Suppose the employee has scores of 2.0 for goal 1, 2.0 for goal 2, 3.0 for goal 3, 2.0 for job effectiveness, 2.0 for competency 1, 3.0 for competency 2, 2.0 for competency 3, 3.0 for competency 4, and 4.0 for core values. Find the weighted average score for this employee. If an employee has a score less than 2.5, they must have a Performance Enhancement Plan written. Does this employee need a plan?

9.  A statistics class has the following activities and weights for determining a grade in the course: test 1 worth 15% of the grade, test 2 worth 15% of the grade, test 3 worth 15% of the grade, homework worth 10% of the grade, semester project worth 20% of the grade, and the final exam worth 25% of the grade. If a student receives an 85 on test 1, a 76 on test 2, an 83 on test 3, a 74 on the homework, a 65 on the project, and a 79 on the final, what grade did the student earn in the course?

10. A statistics class has the following activities and weights for determining a grade in the course: test 1 worth 15% of the grade, test 2 worth 15% of the grade, test 3 worth 15% of the grade, homework worth 10% of the grade, semester project worth 20% of the grade, and the final exam worth 25% of the grade. If a student receives a 92 on test 1, an 85 on test 2, a 95 on test 3, a 92 on the homework, a 55 on the project, and an 83 on the final, what grade did the student earn in the course?

## Measures of Spread



Variability is a fundamental concept in statistics that describes how spread out data values are from each other. Consider measuring the height of everyone in your classroom -- you'll quickly notice that not everyone has the same height. Some students are taller, some are shorter, and there's a range of heights in between. This spread in the data is what we call variability. The same principle applies to other measurements: if you sampled the income levels of people in a town, you'd find that incomes vary widely from person to person.

Understanding variability helps us describe datasets more completely. When data values are clustered closely together, we say there is low variability. When data values are spread far apart, we say there is high variability. To quantify this spread, we need numerical measures that capture how dispersed the data are. This section introduces several measures of variability, also known as measures of variation or spread.

Recall the [example](#exm-mean-median-cats) where we calculated the average weight of a cat to be 2.72 kg. While this tells us the center of the data, it doesn't tell us the whole story. Were most cats close to this weight, or did weights vary dramatically? We know the highest and lowest weights, but what about everything in between? Understanding only the center leaves important questions unanswered.

To fully describe a dataset, we need measures of both center and spread. The measures of variability discussed in this section provide that additional information.


The **range** of a set of data is the difference between the highest and lowest data values (the maximum and minimum values). The **interval** refers to the lowest and highest values themselves. The range is a single value while the interval consists of two values.

::: {#exm-range}
## Calculating the Range
Calculate the range of the body weight of cats.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.
:::

**Solution**
From the effect of extreme values [example](#exm-effect-extreme-values), the maximum weight of a cat was 3.9 kg and the minimum was 2 kg. So the range is $3.9-2=1.9$ kg. But what does that tell you? You don't know if the weights are really spread out, or if they are close together.


Unfortunately, the range does not provide a very accurate picture of variability because it only considers two values: the highest and lowest. A better approach is to examine how far each data value is from the mean. This distance from the mean is called a **deviation**. By looking at all the deviations together, we get a much more complete picture of how spread out the data are.

### Variance and Standard Deviation

To measure the overall spread of data, statisticians calculate the average of the squared deviations from the mean, which is called the **variance**. The variance gives us a single number that captures how dispersed the data values are from the mean. For a population, the variance is denoted by $\sigma^2$ (where $\sigma$ is the Greek letter sigma).

The **population variance** is calculated using the formula:

$$\sigma^2 = \frac{\sum\left(x-\mu \right)^2}{N}$$

where $\mu$ is the population mean, $N$ is the population size, and $\sum$ means to sum all the squared deviations.

While variance is mathematically useful, it has one drawback: it's measured in squared units. For example, if your data are heights measured in centimeters, the variance would be in square centimeters (cm $^2$), which is difficult to interpret. To solve this problem, we take the square root of the variance to get the **standard deviation**, denoted by $\sigma$ for a population.

The **population standard deviation** is:

$$\sigma =\sqrt{ \frac{\sum\left(x-\mu \right)^2}{N}}$$

The standard deviation is measured in the same units as the original data, making it much easier to understand and communicate. If your data are in kilograms, the standard deviation is also in kilograms.

### Sample Variance and Sample Standard Deviation

Since we typically work with samples rather than entire populations, we need sample versions of these measures. The **sample variance**, denoted by $s^2$, is calculated similarly to the population variance but with one important difference: we divide by $n-1$ instead of $n$.

The **sample variance** is:

$$s^2=\frac{\sum\left(x-\bar{x}\right)^2}{n-1}$$

where $\bar{x}$ is the sample mean and $n$ is the sample size.

The reason we use $n-1$ instead of $n$ relates to a statistical concept called degrees of freedom. Using $n-1$ makes the sample variance a better estimate of the population variance. While the mathematical reasoning is complex, the practical result is that dividing by $n-1$ corrects for the bias that would occur if we divided by $n$.

The **sample standard deviation** is simply the square root of the sample variance:

$$s=\sqrt{ \frac{\sum\left(x-\bar{x}\right)^2}{n-1}}$$

Like the population standard deviation, the sample standard deviation is measured in the same units as the original data.

In most real-world situations, we work with samples rather than entire populations, so the **sample variance** ($s^2$) and **sample standard deviation** ($s$) are the measures we use most often in this course. Although we have provided the formulas for the population variance ($\sigma^2$) and population standard deviation ($\sigma$) for reference, our examples and Rguroo instructions will focus on the sample versions. If you ever need to compute population variance or standard deviation, they can be calculated using the [Numerical Summaries]{.fun} function in Rguroo under the **Analytics** toolbox.

### Computing Variance and Standard Deviation

While understanding these formulas is important, in practice you'll typically use technology (such as Rguroo or statistical software) to calculate variance and standard deviation. These tools handle the computations quickly and accurately, allowing you to focus on interpreting the results.

::: {#exm-standard-deviation}
## Calculating the Standard Deviation

For the dataset [cats]{.data} find the variance and standard deviation for weight of cats. Then find the variance and standard deviation separated by sex of the cat.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.
:::

 **Solution**

 When using Rguroo, you would perform similar steps as described in calculation mean and median [example](#Calculating-summary-stats-in-Rguroo), and select [standard deviation]{.def} and [variance]{.def}, as shown in the figure @fig-sd-dialog.

```{r,echo=FALSE}
#| fig-alt: "Dialog box for standard deviation and variance"
#| warning: FALSE
#| label: fig-sd-dialog
#| fig-cap: "Basic Summary Statistic Dialog for Standard Deviation and Variance "
#| out-width: "80%"
knitr::include_graphics("Rguroo_dialogs/Numerical_Description/sd_var_cats_dialog.png")
```


The output is shown in @fig-sd-output. The variance for all cats is 0.24 kg$^2$ and the standard deviation is 0.49 kg.

```{r,echo=FALSE}
#| fig-alt: "Standard Deviation and Variance of Cats Weights"
#| warning: FALSE
#| label: fig-sd-output
#| fig-cap: "Standard Deviation and Variance of Weights of Cats"
#| out-width: "80%"
knitr::include_graphics("Rguroo_outputs/Numerical_Description/sd_var_cats_output.png")
```


To find out the mean, variance, and standard deviation for each sex of the cats, we use a similar function as in @fig-sd-dialog and select sex from the [Factor 1]{.dpd} dropdown, as shown in @fig-spread-sex.

```{r,echo=FALSE}
#| fig-alt: "Mean, Standard Deviation, Variance of Cats Weights by Sex"
#| warning: FALSE
#| label: fig-spread-sex
#| fig-cap: "Mean, Standard Deviation, and Variance of Weights of Cats by Sex"
#| fig-subcap: 
#|   - "Basic Summaries Dialog"
#|   - "Basic Summaries Output"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_description/cat_sex_sdvarmean_dialog.png","Rguroo_outputs/Numerical_Description/cat_sex_sdvarmean_output.png"))
```


You can see that the mean weight of females cats is 2.36 kg, the variance is 0.075 kg$^2$, and the standard deviation is 0.27 kg. For males cats, the mean is 2.9 kg, the variance is 0.22 kg$^2$, and the standard deviation is 0.47 kg. This means that female cats weigh less than males and since the variance and standard deviations are much less for female cats than males cats, female cats' weights are more consistent than male cats.


### Interpreting Variance and Standard Deviation

In general, a "small" variance and standard deviation indicate that data values are close together and more consistent, while a "large" variance and standard deviation indicate that data values are spread out and less consistent. Whether you want high or low variability depends on the context.

For example, if you're manufacturing bolts, you want the lengths to be very consistent. A small standard deviation means the bolts are nearly identical, which is ideal. On the other hand, if you're administering a test to evaluate pilot ability, you want the test scores to show enough variability to distinguish strong candidates from weaker ones. If nearly everyone scores about the same, the standard deviation will be small and it will be difficult to identify the best pilots. A larger standard deviation indicates that scores are more spread out, making it easier to differentiate between high-performing and low-performing candidates.

### What Makes a Standard Deviation "Small" or "Large"?

The meaning of "small" and "large" depends on the context and scale of your data. To a bicyclist whose average speed is 20 mph, a standard deviation of $s = 20$ mph is huge -- it would mean speeds vary wildly from nearly stopped to 40 mph. To an airplane whose average speed is 500 mph, a standard deviation of $s = 20$ mph is quite small, representing only minor variations in cruising speed. The "size" of the standard deviation must always be interpreted relative to the mean and the nature of what you're measuring.


Standard deviations are also meaningful when comparing two samples measured on the same scale. For instance, in the previous [example](#exm-standard-deviation), female cats had a standard deviation of 0.27 kg while male cats had a standard deviation of 0.47 kg. Because both groups are measured in kilograms, we can directly compare these values and conclude that female cat weights are more consistent (less spread out) than male cat weights.


### Using the Standard Deviation


The standard deviation helps describe where the data tend to lie relative to the mean. When the data are symmetric and have most values clustered around a typical center, the empirical rule provides a helpful guideline. It says that about 68% of the data fall within one standard deviation of the mean, about 95% fall within two standard deviations, and about 99.7% fall within three standard deviations. These percentages are not exact, but they often give a reasonable picture of where most of the data lie. @fig-empirical-rule shows how data is distributed according to the empirical rule for a symmetric, bell-shaped distribution.

```{r, echo = FALSE}
#| label: fig-empirical-rule
#| fig-cap: "The Empirical Rule (68-95-99.7 Rule) showing the percentage of data within standard deviations of the mean for symmetric distributions"
#| fig-alt: "Bell curve showing shaded regions for 68%, 95%, and 99.7% of data within 1, 2, and 3 standard deviations from the mean"
knitr::include_graphics("images/empirical_rule.png")
```

For data that are not symmetric, other rules can still be used. Chebyshev's rule gives a minimum proportion of the data that must lie within a certain number of standard deviations of the mean, regardless of the overall shape of the distribution. The results from this rule are usually less precise than those from the empirical rule, but they apply to a much wider range of situations. @fig-chebyshev-rule illustrates Chebyshev's rule, which guarantees at least 75% of data within 2 standard deviations and at least 89% within 3 standard deviations, regardless of distribution shape.

```{r, echo = FALSE}
#| label: fig-chebyshev-rule
#| fig-cap: "Chebyshev's Rule showing minimum percentages of data within k standard deviations of the mean for any distribution"
#| fig-alt: "Non-symmetric distribution showing shaded regions for at least 75% within 2 standard deviations and at least 89% within 3 standard deviations"
knitr::include_graphics("images/chebyshev_rule.png")
```

::: {#exm-empirical-rule}
## Using the Empirical Rule

In the dataset [Tornado_OK]{.data}, the U.S. Weather Service has provided information about the total monthly/annual number of reported tornadoes in Oklahoma for the years 1950 to 2018 (US Department of Commerce & Noaa, 2016). Find the general interval that contains about 95% of the data.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [Tornado_OK]{.data}.
@tbl-Tornado displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-tornado) that follows.
:::

```{r tornado-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Tornado dataset"
#| label: tbl-Tornado
#| tbl-cap: "Monthly/Annual Number of tornadoes in Oklahoma"
Tornado<-read.csv("https://krkozak.github.io/MAT160/Tornado_OK.csv") 
knitr::kable(head(Tornado))
```

::: {#code-book-tornado .callout-tip .codebook collapse="true"}
## Code book for Tornado Dataset

**Description** The U.S. Weather Service has collected data on the monthly and annual number of tornadoes in Oklahoma.

This dataset contains the following columns:

[Year]{.var}: Year from 1950-2018

[Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec]{.var}: Tornado numbers in each month of the year

[Annual]{.var}: Total number of tornadoes for each year

[Source](https://www.weather.gov/oun/tornadodata-ok-1950) US Department of Commerce, & Noaa. (2016, November 15). 1950 Oklahoma Tornadoes.

References The data was supplied by The U.S. Weather Service
:::

**Solution**

Import the [Tornado_OK]{.data} dataset from the [Kozak]{.repo} repository into your Data toolbox on Rguroo using these [directions](#Importing-cats-to-Rguroo).

Variable: $x$ = number of [annual]{.var} tornadoes in Oklahoma

Find the mean and standard deviation as in @fig-tornado-ex:


```{r,echo=FALSE}
#| fig-alt: "Rguroo Dialog Box and Output for Mean and Standard Deviation of Annual Tornadoes"
#| warning: FALSE
#| label: fig-tornado-ex
#| fig-cap: "Mean and Standard Deviation of Annual Tornadoes"
#| fig-subcap: 
#|   - "Basic Summaries Dialog"
#|   - "Basic Summaries Output"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_description/tornado_dialog.png","Rguroo_outputs/Numerical_Description/tornado_output.png"))
```

The mean is $\bar{x}=56$ tornadoes and the standard deviation is $s=27.6$ tornadoes. The interval will be $\bar{x}\pm2\times s=56\pm(2\times27.6)=(0.8,111.2)$

Therefore, we can say that about 95% of the years have between 0.8 or 1 and 111 tornadoes in Oklahoma.


### Identifying Unusual Values with Standard Deviation

The empirical rule tells us that about 95% of data in a symmetric distribution falls within two standard deviations of the mean. This means that data values outside this range are relatively rare -- they occur in only about 5% of cases. We can use this insight to classify data values as common or unusual:

- **Common values**: Data values within two standard deviations of the mean (the middle 95%)
- **Unusual values**: Data values more than two standard deviations away from the mean (the outer 5%)

To determine whether a specific data value is common or unusual, we need to measure how many standard deviations it is from the mean. This standardized distance is called a **z-score** (or $z$-value), and it is calculated using the formula:

$$z=\frac{x-\mu}{\sigma}$$

where $x$ is the data value, $\mu$ is the population mean, and $\sigma$ is the population standard deviation.

The $z$-score tells us how many standard deviations a data value is from the mean. For example, a $z$-score of 2.5 means the data value is 2.5 standard deviations above the mean, while a $z$-score of -1.8 means the data value is 1.8 standard deviations below the mean. Using our rule of thumb:

- If $|z| \leq 2$ (z-score is between -2 and 2), the value is **common**
- If $|z| > 2$ (z-score is less than -2 or greater than 2), the value is **unusual**

In practice, we rarely know the true population parameters $\mu$ and $\sigma$. Instead, we use the sample mean $\bar{x}$ and sample standard deviation $s$ to estimate them:

$$z=\frac{x-\bar{x}}{s}$$

While this sample-based z-score provides a good approximation, keep in mind that it is an estimate and may be less accurate when working with small samples.

::: {#exm-unusual-value}
## Determining If a Value Is Unusual

Using the tornado dataset from the previous [example](#exm-empirical-rule), where the mean number of annual tornadoes in Oklahoma is 56 and the standard deviation is 27.6, determine whether each of the following values is unusual by calculating its $z$-score.

a.  In 1974, there were 45 tornadoes in Oklahoma. Is this value unusual? Why or why not?
b.  In 1999, there were 145 tornadoes in the Oklahoma. Is this value unusual? Why or why not?

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [Tornado_OK]{.data}.
@tbl-Tornado displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-tornado) that follows.
:::

**Solution**

a. Variable: $x$ = number of tornadoes in Oklahoma

To answer this question, first find how many standard deviations 45 is from the mean. From the previous [example](#exm-empirical-rule), we know $\bar{x}=56$ and $s=27.6$. For $x$=45, $z=\frac{45-56}{27.6}=-0.399$

Since this value is between -2 and 2, then it is not unusual to have 45 tornadoes in a year in Oklahoma. The $z$ value is negative, so that means that 45 is less than the mean number of tornadoes.

b. Variable: $x$ = number of tornadoes in Oklahoma

For this question the $x$ = 145, $z=\frac{145-56}{27.6}=3.22$

Since the $z$ value is more than 2, then it would be considered unusual to have 145 tornadoes in a year in Oklahoma.

### Homework for Measures of Spread Section

**Use Rguroo on all problems. State the variable on all problems.**

1.  Cholesterol levels were collected from patients certain days after they had a heart attack and are in @tbl-Cholesterol. Find the mean, median, range, variance, and standard deviation for cholesterol levels 2 days after the heart attack.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cholesterol]{.data}.

**Code book for Data Frame Cholesterol** is below @tbl-Cholesterol.
:::

2.  The lengths (in kilometers) of rivers on the South Island of New Zealand and what body of water they flow into are listed in @tbl-Length (Lee, 1994). Find the mean, median, range, variance, and standard deviation of the length of rivers that flow into the Pacific Ocean and the mean, median, range, variance, and standard deviation of the length of rivers that flow into the Tasman Sea. Compare and contrast the length of rivers that flow to the Pacific Ocean versus the ones that flow into the Tasman Sea using both measures of center and measures of variability.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [length]{.data}.

**Code book for dataset Length** is below @tbl-Length.
:::

3.  Print-O-Matic printing company's employees have salaries that are contained in @tbl-Pay. Find the mean, median, range, variance, and standard deviation for the salaries of all employees.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [pay]{.data}.

**Code book for dataset Pay** below @tbl-Pay.
:::

4.  Print-O-Matic printing company spends specific amounts on fixed costs every month. The costs of those fixed costs are in @tbl-Cost. Find the mean, median, range, variance, and standard deviation for the fixed costs.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cost]{.data}.

**Code book for Data frame Cost** is below @tbl-Cost.
:::

5.  The dataset Pulse @tbl-Pulse contains various variables about a person including their pulse rates before the subject exercised and after the subject ran in place for one minute.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [pulse]{.data}.
:::

```{r pulse-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Pulse dataset"
#| label: tbl-Pulse
#| tbl-cap: "Head of Pulse Rates of people Before and After Exercise"
Pulse<-read.csv("https://krkozak.github.io/MAT160/pulse.csv")
knitr::kable(head(Pulse))
```
::: {#code-book-pulse .callout-tip .codebook collapse="true"}
## Code book for Pulse Dataset

**Description:** Students in an introductory statistics class (MS212 taught by Professor John Eccleston and Dr Richard Wilson at The University of Queensland) participated in a simple experiment. The students took their own pulse rate. They were then asked to flip a coin. If the coin came up heads, they were to run in place for one minute. Otherwise they sat for one minute. Then everyone took their pulse again. The pulse rates and other physiological and lifestyle data are given in the data.

Five class groups between 1993 and 1998 participated in the experiment. The lecturer, Richard Wilson, was concerned that some students would choose the less strenuous option of sitting rather than running even if their coin came up heads, In the years 1995-1998 a different method of random assignment was used. In these years, data forms were handed out to the class before the experiment. The forms were pre-assigned to either running or non-running and there were an equal number of each. In 1995 and 1998 not all of the forms were returned so the numbers running and sitting was still not entirely controlled.

This dataset contains the following columns:

[height]{.var}: height of subject in cm

[weight]{.var}: weight of subject in kg

[age]{.var}: age of subject in years

[gender]{.var}: male or female

[Smokes]{.var}: whether a subject regularly smokes, yes means does smoke, no means does not smoke

[alcohol]{.var}: whether a subject regularly drinks alcohol, yes means the person does, no means the person does not

[exercise]{.var}: whether a subject exercises, low, moderate, high

[ran]{.var}: whether a subject ran one minute between pulse measurements (ran) or sat between pulse measurement (sat)

[pulse_before]{.var}: the pulse rate before a subject either ran or sat (bpm)

[pulse_after]{.var}: the pulse rate after a subject either ran or sat (bpm)

[year]{.var}: what year the data was collected (93-98)

[Source](https://gksmyth.github.io/ozdasl/oz/ms212.html) Pulse rates before and after exercise. (2013, September 25).

References The data was supplied by Dr Richard J. Wilson, Department of Mathematics, University of Queensland.
:::

Create a dataset that contains only males, who drink alcohol, but do not smoke. Then compare the pulse before and the pulse after using the mean and standard deviation. Discuss whether pulse before or pulse after has a higher mean and larger spread. Create the new dataset and save as [pulse_males]{.data} by subsetting the [pulse]{.data} data using the steps described here. See @fig-subset-pulse for the Data Subset Dialog.

```{r,echo=FALSE}
#| fig-alt: "Rguroo Dialog Box for Subsetting Pulse Data"
#| warning: FALSE
#| label: fig-subset-pulse
#| fig-cap: "Subsetting Dialog Box"
#| out-width: "80%"
knitr::include_graphics("Rguroo_dialogs/Numerical_description/pulse_subset_dialog.png")
```

```{r males-filter-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Males dataset"
#| label: tbl-Males
#| tbl-cap: "Head of Pulse Rates of Nonsmoking Males Before and After Exercise"
Males<- Pulse |> 
  filter(gender=="male", smokes == "no", alcohol == "yes")
knitr::kable(head(Males))
```

6.  The dataset Pulse @tbl-Pulse contains various variables about a person including their pulse rates before the subject exercised and after the subject ran in place for one minute. Create a dataset that contains females, who do not smoke but do drink alcohol. Compare the pulse rate before and after exercise using the mean and standard deviation. Discuss whether pulse before or pulse after has a higher mean and larger spread.

7.  To determine if Reiki is an effective method for treating pain, a pilot study was carried out where a certified second-degree Reiki therapist provided treatment on volunteers. Pain was measured using a visual analogue scale (VAS) and a likert scale immediately before and after the Reiki treatment (Olson & Hanson, 1997) and the data is in @tbl-Reiki.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [Reiki_pain]{.data}.
:::

```{r reiki-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Reiki dataset"
#| label: tbl-Reiki
#| tbl-cap: "Head of Pain Measurements Before and After Reiki Treatment"
Reiki<- read.csv( "https://krkozak.github.io/MAT160/reki.csv") 
knitr::kable(head(Reiki))
```

::: {#code-book-reiki .callout-tip .codebook collapse="true"}
## Code book for Reiki Dataset

**Description** The purpose of this study was to explore the usefulness of Reiki as an adjuvant to opioid therapy in the management of pain. Since no studies in this area could be found, a pilot study was carried out involving 20 volunteers experiencing pain at 55 sites for a variety of reasons, including cancer. All Reiki treatments were provided by a certified second-degree Reiki therapist. Pain was measured using both a visual analogue scale (VAS) and a Likert scale immediately before and after the Reiki treatment. Both instruments showed a highly significant (p \< 0.0001) reduction in pain following the Reiki treatment.

This dataset contains the following columns:

[VAS.before]{.var}: pain measured using a visual analogue scale (VAS) before Reiki treatment

[VAS.after]{.var}: pain measured using a visual analogue scale (VAS) after Reiki treatment

[likert_before]{.var}: pain measured using a likert before Reiki treatment

[likert_after]{.var}: pain measured using a likert after Reiki treatment

[Source](http://www.ncbi.nlm.nih.gov/pubmed/9765732) Olson, K., & Hanson, J. (1997). Using reiki to manage pain: a preliminary report. Cancer Prev Control, 1(2), 108-13.

References\*\* Using Reiki to manage pain: a preliminary report. Olson K1, Hanson J., Cancer Prev Control 1997, Jun; 1(2): 108-13.

:::

Since the data was collected both before and after the treatment for all of the units of observations, you want to look at the effect size of the treatment. You want to find the difference between before and after for the pain scale. First you must create a new dataset that adds a column for the difference in before and after. This data is known as paired data. To create the new column in a new dataset called Newreiki use the following steps

:::: {#Transforming-Data-in-Rguroo .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Creating a New Variable in the Reiki_pain Dataset"}
**Before you begin:** Make sure you have already imported the [Reiki_pain]{.data} dataset into your **Data** Toolbox, as was shown [here](#Importing-cats-to-Rguroo).

1.  Open the **Data** toolbox.\
2.  Click on the [Functions]{.dpd} dropdown, and select [Transform]{.fun}. This opens the [Data Transform]{.dialog} dialog.\
3.  From the [Dataset]{.dpd} dropdown, select the [Reiki_pain]{.data} dataset.\
4.  Click on the plus sign icon ![plus icon](Rguroo_Icons/add.png) in the Variable column and type [vas.diff]{.var}. The variable’s name appears in the list labeled Returned Variable on the right side.\
5.  In the middle text field type your R function (transformation). To write a variable name, you can either type it or double-click on the variable name in the Returned Variable list. Double click [VAS.before]{.var} enter minus(-) and double click [VAS.after]{.var}.
6.  When you are done with your selection, click the preview icon ![preview icon](Rguroo_Icons/preview_inline.png) to see the transformed dataset.
7.  In Save As... name the new dataset Newreiki and click the [Save As...]{.button}.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog"}
![Data Transform Dialog in Rguroo](Rguroo_dialogs/Numerical_description/transform_dialog.png){width="500px"} ![Save As... Dataset View](Rguroo_outputs/Numerical_Description/newreiki_dataset.png)
:::
::::

```{r newreiki-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of New Reiki dataset"
#| label: tbl-Newreiki
#| tbl-cap: "Head of Pain Measurements Before and After Reiki Treatment with Difference column"
Newreiki<-Reiki |>
  mutate(vas.diff=vas.before-vas.after) 
knitr::kable(head(Newreiki))
```

Now find the mean and standard deviation of the [vas.diff]{.var} variable in [Newreiki]{.data}. Perform similar commands to create the [likert.diff]{.var} variable. Then find the mean and standard deviation for [likert.diff]{.var}, and compare and contrast the vas and likert methods for describing pain.

8.  Yearly rainfall amounts (in millimeters) in Sydney, Australia, are in @tbl-Rainfall (Annual maximums of, 2013). a. Calculate the mean and standard deviation. b. Suppose Sydney, Australia received 300 mm of rainfall in a year. Would this be unusual?

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [rainfall]{.data}.
:::

```{r rainfall-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Rainfall dataset"
#| label: tbl-Rainfall
#| tbl-cap: "Head of Yearly rainfall amounts in Sydney, Australia"
Rainfall<-read.csv("https://krkozak.github.io/MAT160/rainfall.csv") 
knitr::kable(head(Rainfall))
```

::: {#code-book-rainfall .callout-tip .codebook collapse="true"}
## Code book for Rainfall Dataset

**Description** Daily rainfall (in millimeters) was recorded over a 47-year period in Turramurra, Sydney, Australia. For each year, the wettest day was identified (that having the greatest rainfall). The data show the rainfall recorded for the 47 annual maxima.

This dataset contains the following columns:

[amount]{.var}: daily rainfall (mm)

[Source](https://gksmyth.github.io/ozdasl/oz/sydrain.html) Annual maximums of daily rainfall in Sydney. (2013, September 25).

References Rayner J.C.W. and Best D.J. (1989) Smooth tests of goodness of fit. Oxford: Oxford University Press. Hand D.J., Daly F., Lunn A.D., McConway K.J., Ostrowski E. (1994). A Handbook of Small datasets. London: Chapman & Hall. dataset 157. Thanks to Jim Irish of the University of Technology, Sydney, for assistance in identifying the correct units for this data.

:::

## Ranking

Along with the center and the variability, another useful numerical measure 
is the ranking of a number. A **percentile** is a measure of ranking. It 
represents a location measurement of a data value to the rest of the values. 
Many standardized tests give the results as a percentile. Doctors also use 
percentiles to track a child's growth.

The $k^{th}$ **percentile** is the data value that has $k%$ of the data at or 
below that value.

For instance, a score at the $90^{th}$ percentile means that 90% of the 
scores were at or below this score — in other words, the person did the 
same as or better than 90% of the test takers. A score at the $70^{th}$ 
percentile means that 70% of the scores were at or below this score.

It is important to understand that a percentile is a ranking, not a score. 
If a test was out of 100 points and you scored at the $80^{th}$ percentile, 
that does not mean you earned 80 points. It means you scored the same as or 
better than 80% of the people who took the test. If all the scores were 
really low, you could have still failed the test. On the other hand, if 
many of the scores were high you could have gotten a 95% or more. The 
percentile tells you how you compared to others, not what your actual 
score was.

### Quartiles: Dividing Data into Fourths

While the median divides a dataset into two equal halves, we can also divide data into four equal parts using **quartiles**. Quartiles are special percentiles that split the data into fourths, with one quarter (25%) of the data falling between each consecutive quartile. Just as the median helps us understand the center of the data, quartiles help us understand how the data is distributed across its entire range.

There are three quartiles that divide the data into four equal groups:

- **First quartile (Q1)**: At least 25% of the data values are less than or equal to $Q1$
- **Second quartile (Q2)**: At least 50% of the data values are less than or equal to $Q2$ (this is the median)
- **Third quartile (Q3)**: At least 75% of the data values are less than or equal to $Q3$

Together, these quartiles give us a more complete picture of the data's distribution than the median alone.

**Finding Quartiles in Rguroo**

To find the quartiles in Rguroo, you use the same steps as finding the mean, standard deviation, and variation in Summary Statistic as described [here](#Calculating-summary-stats-in-Rguroo). In the Statistics section of the dialog, simply select the checkboxes for Q1, Q2 (Median), and Q3.


```{r,echo=FALSE}
#| fig-alt: "Dialog for Basic Summary to find Quartiles for Cats Bodyweight in Rguroo"
#| warning: FALSE
#| label: fig-cats-quartiles
#| fig-cap: "Quartiles for Bodyweight of Cats"
#| out-width: "80%"
knitr::include_graphics("Rguroo_dialogs/Numerical_description/quartiles_dialog.png")
```



### The Five-Number Summary

To get a comprehensive picture of how data is distributed, statisticians often use the **five-number summary**, which consists of five key values arranged in order:

1. **Minimum**: The smallest value in the dataset
2. **First quartile (Q1)**: The value at or below which at least 25% of the data falls
3. **Median (Q2)**: The value at or below which at least 50% of the data falls
4. **Third quartile (Q3)**: The value at or below which at least 75% of the data falls
5. **Maximum**: The largest value in the dataset

Together, these five numbers give us a complete snapshot of the data's spread from lowest to highest.

### Interquartile Range (IQR)

The **interquartile range (IQR)** measures the spread of the middle 50% of the data. It is calculated as:

$$IQR = Q_3 - Q_1$$

The IQR tells us how spread out the central portion of the data is. A large IQR indicates that the middle half of the data is widely spread, while a small IQR suggests the data is more tightly clustered around the median. Because the IQR focuses on the middle 50% of the data, it is not affected by extreme values, making it a robust measure of spread.

### Identifying Outliers Using the IQR

The IQR can also help us identify **outliers** -- data values that are unusually far from the rest of the data. To do identify potential outliers using the IQR, we create boundaries called **fences**:

- **Lower fence** = $Q_1 - 1.5 \times IQR$
- **Upper fence** = $Q_3 + 1.5 \times IQR$

Any data value below the lower fence or above the upper fence is considered a potential outlier. These values are far enough from the bulk of the data that they warrant special attention, as they may represent unusual observations, measurement errors, or genuinely exceptional cases.

### Boxplots: Visualizing the Five-Number Summary

A **boxplot** (also called a box-and-whisker plot) provides a visual representation of the five-number summary and makes it easy to see the distribution of data at a glance. Here's how to read a boxplot:

**Basic boxplot structure:**
- A rectangular **box** extends from Q1 to Q3, containing the middle 50% of the data
- A line inside the box marks the **median**
- **Whiskers** (lines) extend from the box to the minimum and maximum values
- The horizontal axis shows the scale of the variable being measured

**Modified boxplot (more common):**
In a modified boxplot, the whiskers are shortened to show only the data within the fences:
- The left whisker extends to the smallest value that is still above the lower fence
- The right whisker extends to the largest value that is still below the upper fence
- **Outliers** beyond the fences are shown as individual points (dots, circles, or asterisks)

This modified version makes it easier to spot outliers and see the typical range of the data.

### Interpreting Shape from Boxplots

Boxplots also reveal information about the shape of the distribution. @fig-boxplot-comparison illustrates how different distribution shapes appear in boxplots.

```{r,echo=FALSE}
#| fig-alt: "example of skewed right, symmetric, and skewed left boxplots"
#| warning: FALSE
#| label: fig-boxplot-comparison
#| fig-cap: "Comparing Shapes of Boxplots"
#| fig-subcap: 
#|  - "Boxplots showing three distribution shapes"
#|  - "Corresponding histograms for comparison"
#| out-width: "80%"
knitr::include_graphics(c("images/boxplot_comparison.png","images/boxplot_histogram_comparison.png"))
```

**Symmetric distribution:**
- The box appears balanced around the median
- Both whiskers are approximately the same length
- The median line is near the center of the box

**Skewed left:**
- The left whisker is noticeably longer than the right
- The median is shifted toward the right side of the box (toward Q3)

**Skewed right:**
- The right whisker is noticeably longer than the left
- The median is shifted toward the left side of the box (toward Q1)

If a boxplot is symmetric with long whiskers relative to the size of the box, the distribution may have a bell shape with data concentrated near the center and thin tails. However, a symmetric boxplot alone is not sufficient to confirm a bell-shaped distribution.

::: {#exm-fivenumbersummary-boxplots}
## Five-number Summary and Boxplot

Find the five-number summary, the interquartile range ($IQR$), and draw a box-and-whiskers plot for the weight of cats @tbl-Cats.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.

:::

**Solution**

Variable: $x$ = weight of cats

To compute the five-number summary on Rguroo, use summary statistic and select the appropriate statistics as shown in @fig-cats-5numsum


```{r,echo=FALSE}
#| fig-alt: "Five-Number Summary for Cats Bodyweight"
#| warning: FALSE
#| label: fig-cats-5numsum
#| fig-cap: "Five-Number Summary for Bodyweight of Cats"
#| fig-subcap: 
#|   - "Basic Summary Dialog Box"
#|   - "Five-Number Summary Output"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_description/cats_5numsum_dialog.png","Rguroo_outputs/Numerical_Description/cats_5numsum_output.png"))
```


Minimum: 2 kg $Q1$: 2.3 kg Median: 2.7 kg $Q3$: 3.025 kg Maximum: 3.9 kg

To find the interquartile range, $IQR$ find $Q3-Q1$, so $IQR=3.025-2.3=0.725 kg$

Click to expand the box below to see instructions to create a boxplot of the [cats]{.data} dataset in Rguroo.

:::: {#Creating-a-boxplot-in-Rguroo .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Creating a Boxplot of the Bodyweight of Cats"}
**Before you begin:** Make sure you have already imported the [cats]{.data} dataset into your **Data** Toolbox, as was shown [here](#Importing-cats-to-Rguroo).

1.  Open the **Plots** toolbox.\
2.  Click on the [Create Plot]{.dpd} dropdown menu and choose the [Boxplot]{.fun} function. The Boxplot dialog will open.
3.  From the [Dataset]{.dpd} dropdown, select the [cats]{.data} dataset.\
4.  Move the [Bwt]{.var} variables to the Selected column.\
5.  Click the preview icon ![preview icon](Rguroo_Icons/preview_inline.png) to see the graph.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog"}
![Boxplot dialog in Rguroo](Rguroo_dialogs/Numerical_description/cats_boxplot_dialog.png){width="500px"}
:::
::::


This is a modified boxplot which shows the outliers in the data.

```{r cats1-data-box, eval = FALSE, echo = FALSE}
#| fig-alt: "box plot of weight of Cats median 2.7, Q1 at 2.3, lower fence at 2.0, Q3 at 3.0, upper fence at 3.8."
#| warning: FALSE
#| label: fig-Cats-boxplot
#| fig-cap: "Weight of Cats"
# gf_boxplot(~Bwt, data=cats, title="Weight of Cats", xlab="Body Weight (kg)")

```

::: {.rg-iframe-wrapper tabindex="0"}
<iframe src="Rguroo_html_output/Numerical_description/Boxplot_12/Boxplot_12.html" class="rg-iframe" title="Boxplot for Weight of Cats">

</iframe>
:::

There are no outliers since there are no dots outside of the fences.

::: {#exm-boxplots-factor}
## Separating based on a factor

Find the five-number summary of the weights of cats separated by the sex of the cat. Then create a box plot of the weights of cats for each sex of the cat.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cats]{.data}.
@tbl-Cats displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-cats) that follows.

:::

**Solution**

Variable: $x_1$ = weight of female cat

Variable: $x_2$ = weight of male cat

The five-number summary separated based on gender can be found in a similar way as in the previous [example](#exm-fivenumbersummary-boxplots):


```{r,echo=FALSE}
#| fig-alt: "Five-Number Summary of weight of Cats female lower 2.0, Q1 22, Median 2.3, Q3 3.0, upper 3.0, male 2.0, 2.5, 2.9, 3, 3.8"
#| warning: FALSE
#| label: fig-cats-5numsumsex
#| fig-cap: "Five-Number Summary for Bodyweight of Cats by Sex"
#| fig-subcap: 
#|   - "Basic Summary Dialog Box"
#|   - "Five-Number Summary Output"
#| out-width: "80%"
knitr::include_graphics(c("Rguroo_dialogs/Numerical_description/5summary_cats_sex_dialog.png","Rguroo_outputs/Numerical_Description/cats_5summ_sex_output.png"))
```

The five-number summary for female cats is (in kg)

Minimum: 2 $Q1$: 2.15 Median: 2.3 $Q3$: 2.5 Maximum: 3.0

The five-number summary for male cats is (in kg)

Minimum: 2 $Q1$: 2.50 Median: 2.9 $Q3$: 3.2 Maximum: 3.9

```{r cats2-data-box, eval = FALSE, echo = FALSE}
#| fig-alt: "box plot of weight of Cats female lower 2.0, Q1 22, Median 2.3, Q3 3.0, upper 3.0, male 2.0, 2.5, 2.9, 3, 3.8"
#| warning: FALSE
#| label: fig-Cats-boxplot-sex
#| fig-cap: "Weight of Cats Faceted by Sex"
gf_boxplot(~Bwt|Sex, data=cats, title="Weights of Cats", xlab="Body Weight in (kg)") 
```

::: {.rg-iframe-wrapper tabindex="0"}
<iframe src="Rguroo_html_output/Numerical_description/Boxplot_8/Boxplot_8.html" class="rg-iframe" title="Boxplot for Weight of Cats by Sex">

</iframe>
:::

Notice that the weights of female cats has a median less than male cats, and in fact it can be seen that the $Q1$ to $Q3$ of the female cats is less than the $Q1$ to $Q3$ of the male cats.

::: {#exm-putting-it-together}
## Putting it all together

The time (in 1/50 seconds) between successive pulses along a nerve fiber ("Time between nerve," 2013) are given in @tbl-Nerve.

![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this example is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [nerve]{.data}.
@tbl-Nerve displays the first six rows of the dataset. A complete description of the variables is provided in the  [dataset code book](#code-book-nerve) that follows.
:::

```{r nerve-data, echo = FALSE}
#| tbl-alt: "Table showing first 6 rows of Nerve dataset"
#| label: tbl-Nerve
#| tbl-cap: "Head of Successive pulses along a nerve fiber"
Nerve<-read.csv( "https://krkozak.github.io/MAT160/Nerve_pulse.csv") 
knitr::kable(head(Nerve))
```

::: {#code-book-nerve .callout-tip .codebook collapse="true"}
## Code book for Nerve Dataset

**Description** The data gives the time between 800 successive pulses along a nerve fiber. There are 799 observations rounded to the nearest half in units of 1/50 second.

This dataset contains the following columns:

[time]{.var}: time between successive Pulses along a nerve fiber, 1/50 second.

[Source](https://gksmyth.github.io/ozdasl/general/nerve.html) Time between nerve pulses. (2019, July 3).

References Fatt, P., and Katz, B. (1952). Spontaneous subthreshold activity at motor nerve endings. Journal of Physiology 117, 109-128.

Cox, D. R., and Lewis, P. A. W. (1966). The Statistical Analysis of Series of Events. Methuen, London.

Jorgensen, B. (1982). The Generalized Inverse-Gaussian Distribution. Springer-Verlag.

:::


**Solution**

First, it might be useful to look at a visualization of the data, so create a density plot

```{r density-data-density, echo = FALSE, eval = FALSE}
#| fig-alt: "Density plot with peak on left and lower on the right"
#| warning: FALSE
#| label: fig-Pulse-density-1
#| fig-cap: "Weight of Cats Faceted by Sex"
gf_density(~time, data=Nerve, title="Time between Successive Nerve Pulses", xlab="Time (1/50 second)") 
```

Click to expand the box below to see instructions to create a density plot of the [nerve]{.data} dataset in Rguroo.

:::: {#Creating-a-density-plot-in-Rguroo .callout-note appearance="simple" collapse="true" icon="none" title="![](Rguroo_Icons/R_circle_logo.svg){width=22px style='vertical-align:middle;'} Creating a Density Plot of the Time Between Successive Nerve Pulses"}
**Before you begin:** Make sure you have already imported the [nerve]{.data} dataset into your **Data** Toolbox, as was shown [here](#Importing-cats-to-Rguroo).

1.  Open the **Plots** toolbox.\
2.  Click on the [Create Plot]{.dpd} dropdown menu and choose the [Histogram]{.fun} function. The Histogram dialog will open.
3.  From the [Dataset]{.dpd} dropdown, select the [nerve]{.data} dataset.\
4.  Move the [time]{.var} variables to the Selected column.\
5.  Select density in Type and density in Smoothing additional options.
6.  Click the preview icon ![preview icon](Rguroo_Icons/preview_inline.png) to see the graph.

::: {.callout-note appearance="simple" collapse="true" icon="none" title="Click here to see the Rguroo dialog"}
![Boxplot dialog in Rguroo](Rguroo_dialogs/Numerical_description/nerve_density_dialog.png){width="500px"}
:::
::::

::: {.rg-iframe-wrapper tabindex="0"}
<iframe src="Rguroo_html_output/Numerical_description/Histogram_7/Histogram_7.html" class="rg-iframe" title="Density Plot for Successive Nerve Pulses">

</iframe>
:::

From the graph, the data appears to be skewed right. Most of the time, between successive nerve pulses appear to be around 5 or 10 1/50 second, but there are some times that are 60 1/50 second.

```{r statistics-nerve, echo = FALSE, eval = FALSE}
df_stats(~time, data=Nerve, mean, median, sd, summary)
```

```{r, echo = FALSE }
#| fig-alt: "Five-Number Summary with Mean and Standard Deviation of Nerve Pulses"
#| warning: FALSE
#| label: fig-Pulse-summary
#| fig-cap: "Numerical Summary of Time Between Successive Nerve Pulses"
#| out-width: "80%"
knitr::include_graphics("Rguroo_outputs/Numerical_Description/nerve_summary_output.png")
```

Numerical descriptions might also be useful. Using technology, the mean is 11 1/50 second,the median is 7.5 1/50 second, the standard deviation is 10.5 1/50 second, and the five-number summary is minimum = 0.5, Q1 = 3.5, median = 7.5, Q3 = 15, and maximum = 69 1/50 second.

To visualize the five-number summary, create a box plot using the instructions given [here](#Creating-a-boxplot-in-Rguroo).

```{r nerve-data-box, echo = FALSE, eval = FALSE}
#| fig-alt: "box plot lower fence 0, Q1 5, median 8, Q3 17, upper fence 31, many outliers above upper fence"
#| warning: FALSE
#| label: fig-Nerve-box
#| fig-cap: "Boxplot of Nerve Pulses"
gf_boxplot(~time, data=Nerve, title="Nerve Pulses", xlab="Time (1/50 second)")
```

```{r, echo = FALSE }
#| fig-alt: "Boxplot of Nerve Pulses"
#| warning: FALSE
#| label: fig-nerve-boxplot
#| fig-cap: "Boxplot of Time Between Successive Nerve Pulses"
#| out-width: "80%"
knitr::include_graphics("Rguroo_outputs/Numerical_Description/nerve_boxplot_output.svg")
```


The boxplot reveals multiple high outliers. The mean shows a typical pulse interval of 11 1/50 seconds, with an IQR of 19.5 1/50 seconds indicating substantial variability. The right skew visible in both plots confirms that while most pulses occur consistently around 11 1/50 seconds, occasional longer delays create the high outliers.

### Homework for Ranking Section

**Use Rguroo on all problems. State the variable on all problems.**

1.  Suppose you take a standardized test and you are in the $10^{th}$ percentile. What does this percentile mean? Can you say that you failed the test? Explain.

2.  Suppose your child takes a standardized test in mathematics and scores in the $96^{th}$ percentile. What does this percentile mean? Can you say your child passed the test? Explain.

3.  Suppose your child is in the $83^{rd}$ percentile in height and $24^{th}$ percentile in weight. Describe what this tells you about your child's stature.

4.  Suppose your work evaluates the employees and places them on a percentile ranking. If your evaluation is in the $65^{th}$ percentile, do you think you are working hard enough? Explain.

5.  Cholesterol levels were collected from patients certain days after they had a heart attack and are in table @tbl-Cholesterol.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [cholesterol]{.data}.

**Code book for Data Frame Cholesterol** below @tbl-Cholesterol.
:::

Find the five-number summary and interquartile range (IQR) for the cholesterol level on day 2, and draw a boxplot

6.  The lengths (in kilometers) of rivers on the South Island of New Zealand and what body of water they flow into are listed in table @tbl-Length (Lee, 1994).

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [length]{.data}.

**Code book for dataset Length** below @tbl-Length.
:::

Find the five-number summary and interquartile range (IQR) for the lengths of rivers that go to the Pacific Ocean and ones that go to the Tasman Sea, and draw a boxplot of both.

7.  Print-O-Matic printing company's employees have salaries that are contained in @tbl-Pay Find the five number summary and draw a boxplot for the salaries of all employees.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [pay]{.data}.

**Code book for dataset Pay** below @tbl-Pay.
:::

8.  The dataset Pulse @tbl-Pulse contains various variables about a person including their pulse rates before the subject exercised and after after the subject ran in place for one minute.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [pulse]{.data}.

**Code book for dataset Pulse** below @tbl-Pulse.
:::

Create a dataset that contains only people who drink alcohol, but do not smoke. Then find the five number summary and draw a boxplot for both males and females separately.

9.  To determine if Reiki is an effective method for treating pain, a pilot study was carried out where a certified second-degree Reiki therapist provided treatment on volunteers. Pain was measured using a visual analogue scale (VAS) and a Likert scale immediately before and after the Reiki treatment (Olson & Hanson, 1997) and the data is in @tbl-Reiki.

::: {tabindex="0" style="width:85%; margin:auto;"}
![Rguroo dataset logo](Rguroo_Icons/Rguroo_repo_logo.png) The dataset for this exercise is available in the Rguroo dataset repository [Kozak]{.repo}, with the dataset name [Reiki_pain]{.data}.

**Code book for dataset Reiki** below @tbl-Reiki.
:::

Find the five number summary for both the before and after VAS scores and draw boxplots of before and after VAS scores. 

Compare and contrast the before and after VAS scores.